{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, plot_confusion_matrix\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
    "from dagmm_INSE_6180 import DAGMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To plot pretty figures\n",
    "%matplotlib inline\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "mpl.rc('axes', labelsize=14)\n",
    "mpl.rc('xtick', labelsize=12)\n",
    "mpl.rc('ytick', labelsize=12)\n",
    "\n",
    "# Where to save the figures\n",
    "PROJECT_ROOT_DIR = \".\"\n",
    "IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, \"images\")\n",
    "os.makedirs(IMAGES_PATH, exist_ok=True)\n",
    "\n",
    "def save_fig(fig_id, tight_layout=True, fig_extension=\"png\", resolution=300):\n",
    "    path = os.path.join(IMAGES_PATH, fig_id + \".\" + fig_extension)\n",
    "    print(\"Saving figure\", fig_id)\n",
    "#     if tight_layout:\n",
    "#         plt.tight_layout()\n",
    "    plt.savefig(path, format=fig_extension, dpi=resolution, bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiement 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = './datasets/chiller/df_dataset/'\n",
    "\n",
    "def load_data(load_path, filename):\n",
    "    csv_load_path = os.path.join(load_path, filename)\n",
    "    return pd.read_csv(csv_load_path)\n",
    "\n",
    "data_1 = load_data(load_path, 'chiller10.csv')\n",
    "data_11, data_12 = train_test_split(data_1, test_size=0.2, random_state=0)\n",
    "X_12, y_12  = data_12.iloc[:, :-1], data_12.iloc[:, -1] \n",
    "columns = X_12.columns\n",
    "# choices = np.random.choice(X_12.size, 2*X_12.shape[0], replace=False)\n",
    "# X_12_flatted = X_12.to_numpy().ravel()\n",
    "# X_12_flatted[choices] = 500\n",
    "choices = np.random.choice(X_12.size, 2*X_12.shape[0], replace=False)\n",
    "X_12_flatted = X_12.to_numpy().ravel()\n",
    "X_12_flatted[choices] = 500\n",
    "X_12 = pd.DataFrame(X_12_flatted.reshape(X_12.shape))\n",
    "X_12.columns = columns\n",
    "data_12 = X_12.copy()\n",
    "data_12['label'] = np.asarray(y_12, dtype=int)\n",
    "data = data_11.append(data_12)\n",
    "data = data.drop('Unnamed: 0', axis='columns')\n",
    "data_trn, data_tst = train_test_split(data, test_size=0.5, random_state=0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset 1 - Origninal data\n",
    "\n",
    "X_trn, y_trn = data_trn.iloc[:, :-1], data_trn.iloc[:, -1]\n",
    "X_tst, y_tst = data_tst.iloc[:, :-1], data_tst.iloc[:, -1]\n",
    "# Scaling data\n",
    "scaler_d1 = StandardScaler().fit(X_trn)\n",
    "X_trn_scaled, X_tst_scaled = scaler_d1.transform(X_trn), scaler_d1.transform(X_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\travi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2584/2584 [==============================] - mean_loss: 101.2083 - val_loss: 69.5037\n",
      "Best Epoch: 1\n",
      "Epoch 2/5\n",
      "2584/2584 [==============================] - mean_loss: 64.4193 - val_loss: 64.9874\n",
      "Best Epoch: 2\n",
      "Epoch 3/5\n",
      "2584/2584 [==============================] - mean_loss: 62.6662 - val_loss: 63.5876\n",
      "Best Epoch: 3\n",
      "Epoch 4/5\n",
      "2584/2584 [==============================] - mean_loss: 61.1903 - val_loss: 62.1453\n",
      "Best Epoch: 4\n",
      "Epoch 5/5\n",
      "2584/2584 [==============================] - mean_loss: 59.2285 - val_loss: 61.2962\n",
      "Best Epoch: 5\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\travi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2571/2571 [==============================] - mean_loss: 80.3598 - val_loss: 62.7119\n",
      "Best Epoch: 1\n",
      "Epoch 2/5\n",
      "2571/2571 [==============================] - mean_loss: 61.6228 - val_loss: 59.3595\n",
      "Best Epoch: 2\n",
      "Epoch 3/5\n",
      "2571/2571 [==============================] - mean_loss: 56.5746 - val_loss: 58.1229\n",
      "Best Epoch: 3\n",
      "Epoch 4/5\n",
      "2571/2571 [==============================] - mean_loss: 50.0241 - val_loss: 58.2418\n",
      "Best Epoch: 3\n",
      "Epoch 5/5\n",
      "2571/2571 [==============================] - mean_loss: 52.7264 - val_loss: 57.5215\n",
      "Best Epoch: 5\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\travi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2568/2568 [==============================] - mean_loss: 81.0728 - val_loss: 53.0887\n",
      "Best Epoch: 1\n",
      "Epoch 2/5\n",
      "2568/2568 [==============================] - mean_loss: 66.3676 - val_loss: 50.2661\n",
      "Best Epoch: 2\n",
      "Epoch 3/5\n",
      "2568/2568 [==============================] - mean_loss: 59.8169 - val_loss: 48.5356\n",
      "Best Epoch: 3\n",
      "Epoch 4/5\n",
      "2568/2568 [==============================] - mean_loss: 57.2611 - val_loss: 49.0354\n",
      "Best Epoch: 3\n",
      "Epoch 5/5\n",
      "2568/2568 [==============================] - mean_loss: 52.7197 - val_loss: 47.7389\n",
      "Best Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\travi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2607/2607 [==============================] - mean_loss: 82.5916 - val_loss: 60.9396\n",
      "Best Epoch: 1\n",
      "Epoch 2/5\n",
      "2607/2607 [==============================] - mean_loss: 63.9746 - val_loss: 57.8933\n",
      "Best Epoch: 2\n",
      "Epoch 3/5\n",
      "2607/2607 [==============================] - mean_loss: 54.8406 - val_loss: 56.2334\n",
      "Best Epoch: 3\n",
      "Epoch 4/5\n",
      "2607/2607 [==============================] - mean_loss: 58.8326 - val_loss: 55.4768\n",
      "Best Epoch: 4\n",
      "Epoch 5/5\n",
      "2607/2607 [==============================] - mean_loss: 58.8122 - val_loss: 54.0538\n",
      "Best Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\travi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2592/2592 [==============================] - mean_loss: 89.9101 - val_loss: 58.3905\n",
      "Best Epoch: 1\n",
      "Epoch 2/5\n",
      "2592/2592 [==============================] - mean_loss: 66.3326 - val_loss: 55.1863\n",
      "Best Epoch: 2\n",
      "Epoch 3/5\n",
      "2592/2592 [==============================] - mean_loss: 61.4632 - val_loss: 54.7953\n",
      "Best Epoch: 3\n",
      "Epoch 4/5\n",
      "2592/2592 [==============================] - mean_loss: 59.8451 - val_loss: 53.5469\n",
      "Best Epoch: 4\n",
      "Epoch 5/5\n",
      "2592/2592 [==============================] - mean_loss: 55.2257 - val_loss: 53.6350\n",
      "Best Epoch: 4\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\travi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2616/2616 [==============================] - mean_loss: 79.1266 - val_loss: 58.0991\n",
      "Best Epoch: 1\n",
      "Epoch 2/5\n",
      "2616/2616 [==============================] - mean_loss: 60.4920 - val_loss: 54.9888\n",
      "Best Epoch: 2\n",
      "Epoch 3/5\n",
      "2616/2616 [==============================] - mean_loss: 61.6231 - val_loss: 53.3462\n",
      "Best Epoch: 3\n",
      "Epoch 4/5\n",
      "2616/2616 [==============================] - mean_loss: 57.1579 - val_loss: 51.4512\n",
      "Best Epoch: 4\n",
      "Epoch 5/5\n",
      "2616/2616 [==============================] - mean_loss: 56.0470 - val_loss: 51.9060\n",
      "Best Epoch: 4\n",
      "Epoch 1/5\n",
      " 128/2635 [=>............................] - mean_loss: 222.8342"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\travi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2635/2635 [==============================] - mean_loss: 96.0777 - val_loss: 55.4076\n",
      "Best Epoch: 1\n",
      "Epoch 2/5\n",
      "2635/2635 [==============================] - mean_loss: 67.8162 - val_loss: 53.2934\n",
      "Best Epoch: 2\n",
      "Epoch 3/5\n",
      "2635/2635 [==============================] - mean_loss: 56.7900 - val_loss: 51.1243\n",
      "Best Epoch: 3\n",
      "Epoch 4/5\n",
      "2635/2635 [==============================] - mean_loss: 53.6084 - val_loss: 50.5110\n",
      "Best Epoch: 4\n",
      "Epoch 5/5\n",
      "2635/2635 [==============================] - mean_loss: 57.1873 - val_loss: 50.1333\n",
      "Best Epoch: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\travi\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\keras\\optimizer_v2\\optimizer_v2.py:374: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "2591/2591 [==============================] - mean_loss: 84.3829 - val_loss: 45.7531\n",
      "Best Epoch: 1\n",
      "Epoch 2/5\n",
      "2591/2591 [==============================] - mean_loss: 59.7520 - val_loss: 43.3794\n",
      "Best Epoch: 2\n",
      "Epoch 3/5\n",
      "2591/2591 [==============================] - mean_loss: 63.5476 - val_loss: 42.5697\n",
      "Best Epoch: 3\n",
      "Epoch 4/5\n",
      "2591/2591 [==============================] - mean_loss: 57.4512 - val_loss: 41.4679\n",
      "Best Epoch: 4\n",
      "Epoch 5/5\n",
      "2591/2591 [==============================] - mean_loss: 59.0418 - val_loss: 41.6331\n",
      "Best Epoch: 4\n"
     ]
    }
   ],
   "source": [
    "# Dataset 2 - Cleaning data using multiclass DAGMM\n",
    "model_dagmms = []\n",
    "data_rate = 80\n",
    "data_trn_clean_d2 = pd.DataFrame()\n",
    "energy_thresholds = []\n",
    "\n",
    "# Offline phase\n",
    "n = len(data_trn['label'].unique())\n",
    "for i in range(n):\n",
    "    model_dagmm = DAGMM(comp_hiddens=[50, 30, 20, 10], comp_activation=\"elu\",\n",
    "                      est_hiddens=[15, 3], est_activation=\"elu\", est_dropout_ratio=0.2,\n",
    "                      n_epochs=5, batch_size=128, normalize=True)\n",
    "    data_trn_c, X_trn_c = data_trn[y_trn==i], X_trn[y_trn==i]\n",
    "    model_dagmm.build(X_trn_c)\n",
    "    model_dagmm.fit(X_trn_c)\n",
    "    energy = model_dagmm.predict(X_trn_c)\n",
    "    energy_threshold = np.percentile(energy, data_rate)\n",
    "    data_trn_clean_d2 = data_trn_clean_d2.append(data_trn_c[energy <= energy_threshold])\n",
    "    model_dagmms.append(model_dagmm)\n",
    "    energy_thresholds.append(energy_threshold)\n",
    "\n",
    "X_trn_clean_d2, y_trn_clean_d2 = data_trn_clean_d2.iloc[:, :-1], data_trn_clean_d2.iloc[:, -1]\n",
    "\n",
    "# Online phase\n",
    "energies = []\n",
    "for i in range(len(model_dagmms)):\n",
    "    energy = model_dagmms[i].predict(X_tst)\n",
    "    energies.append(energy)\n",
    "\n",
    "energies_np = np.asanyarray(energies)\n",
    "\n",
    "energy_thresholds_np = np.asarray(energy_thresholds).reshape(-1, 1)\n",
    "votes = np.where(energies_np > energy_thresholds_np, 1, 0).T\n",
    "votes_sum = np.sum(votes, axis=1)\n",
    "idx_outlier = np.where(votes_sum >= 5)\n",
    "idx = np.where(votes_sum <= 5) # normal data index\n",
    "data_tst_clean_d2 = data_tst.iloc[idx]\n",
    "X_tst_clean_d2, y_tst_clean_d2 = data_tst_clean_d2.iloc[:, :-1], data_tst_clean_d2.iloc[:, -1]\n",
    "\n",
    "# Scaling data\n",
    "scaler_d2 = StandardScaler().fit(X_trn_clean_d2)\n",
    "X_trn_clean_scaled_d2, X_tst_clean_scaled_d2 = scaler_d2.transform(X_trn_clean_d2), scaler_d2.transform(X_tst_clean_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16610, 65), (16015, 65))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # Dataset 1 - Original dataset\n",
    "# X_trn_, X_tst_ = X_trn, X_tst\n",
    "# X_trn_scaled_, X_tst_scaled_ = X_trn_scaled, X_tst_scaled\n",
    "# y_trn_, y_tst_ = y_trn, y_tst\n",
    "\n",
    "# Dataset 2 - Cleaning data using multiclass DAGMM\n",
    "X_trn_, X_tst_ = X_trn_clean_d2, X_tst_clean_d2\n",
    "X_trn_scaled_, X_tst_scaled_ = X_trn_clean_scaled_d2, X_tst_clean_scaled_d2\n",
    "y_trn_, y_tst_ = y_trn_clean_d2, y_tst_clean_d2\n",
    "\n",
    "X_trn_.shape, X_tst_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN MODEL:\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:   46.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=3, p=1)\n",
      "Train Accuracy: 99.42805538832029 %\n",
      "Test Accuracy: 97.70839837652201 %\n",
      "====================================================================\n",
      "Confusion matrix: \n",
      " [[2054    7    2   26    5    6    0    0]\n",
      " [  25 1769    0    3    3    0    0    0]\n",
      " [  22    0 2079    0    0    0    0    0]\n",
      " [  44    4    0 2003   35   10    0    0]\n",
      " [   8    0    0   49 1917   23    0    0]\n",
      " [  13    0    0   29   13 1909    0    0]\n",
      " [   9    0    0    3    3    4 1853    1]\n",
      " [   7    0    0    2    4    0    7 2064]]\n",
      "====================================================================\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9413    0.9781    0.9594      2100\n",
      "           1     0.9938    0.9828    0.9883      1800\n",
      "           2     0.9990    0.9895    0.9943      2101\n",
      "           3     0.9470    0.9556    0.9513      2096\n",
      "           4     0.9682    0.9599    0.9640      1997\n",
      "           5     0.9780    0.9720    0.9750      1964\n",
      "           6     0.9962    0.9893    0.9928      1873\n",
      "           7     0.9995    0.9904    0.9949      2084\n",
      "\n",
      "    accuracy                         0.9771     16015\n",
      "   macro avg     0.9779    0.9772    0.9775     16015\n",
      "weighted avg     0.9774    0.9771    0.9772     16015\n",
      "\n",
      "====================================================================\n",
      "SVM MODEL:\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC(C=8, gamma=0.25)\n",
      "Train Accuracy: 99.99397953040338 %\n",
      "Test Accuracy: 98.4264751795192 %\n",
      "====================================================================\n",
      "Confusion matrix: \n",
      " [[2057    0    0   23   15    5    0    0]\n",
      " [  11 1767    0    0   22    0    0    0]\n",
      " [   0    0 2095    0    6    0    0    0]\n",
      " [  23    0    0 2021   42    9    1    0]\n",
      " [   6    0    0   18 1967    6    0    0]\n",
      " [   3    0    0    6   13 1942    0    0]\n",
      " [   1    0    0    0   13    0 1855    4]\n",
      " [   2    0    0    0   22    0    1 2059]]\n",
      "====================================================================\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9781    0.9795    0.9788      2100\n",
      "           1     1.0000    0.9817    0.9907      1800\n",
      "           2     1.0000    0.9971    0.9986      2101\n",
      "           3     0.9773    0.9642    0.9707      2096\n",
      "           4     0.9367    0.9850    0.9602      1997\n",
      "           5     0.9898    0.9888    0.9893      1964\n",
      "           6     0.9989    0.9904    0.9946      1873\n",
      "           7     0.9981    0.9880    0.9930      2084\n",
      "\n",
      "    accuracy                         0.9843     16015\n",
      "   macro avg     0.9849    0.9843    0.9845     16015\n",
      "weighted avg     0.9846    0.9843    0.9844     16015\n",
      "\n",
      "====================================================================\n",
      "RANDOM FOREST MODEL:\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   35.4s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:   35.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(n_estimators=350)\n",
      "Train Accuracy: 100.0 %\n",
      "Test Accuracy: 99.87511707773962 %\n",
      "====================================================================\n",
      "Confusion matrix: \n",
      " [[2097    0    0    3    0    0    0    0]\n",
      " [   0 1800    0    0    0    0    0    0]\n",
      " [   0    0 2101    0    0    0    0    0]\n",
      " [  12    0    0 2081    0    2    1    0]\n",
      " [   0    0    0    0 1997    0    0    0]\n",
      " [   0    0    0    0    0 1964    0    0]\n",
      " [   0    0    0    0    0    0 1873    0]\n",
      " [   0    0    0    0    2    0    0 2082]]\n",
      "====================================================================\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9943    0.9986    0.9964      2100\n",
      "           1     1.0000    1.0000    1.0000      1800\n",
      "           2     1.0000    1.0000    1.0000      2101\n",
      "           3     0.9986    0.9928    0.9957      2096\n",
      "           4     0.9990    1.0000    0.9995      1997\n",
      "           5     0.9990    1.0000    0.9995      1964\n",
      "           6     0.9995    1.0000    0.9997      1873\n",
      "           7     1.0000    0.9990    0.9995      2084\n",
      "\n",
      "    accuracy                         0.9988     16015\n",
      "   macro avg     0.9988    0.9988    0.9988     16015\n",
      "weighted avg     0.9988    0.9988    0.9988     16015\n",
      "\n",
      "====================================================================\n",
      "ADABOOST MODEL:\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  27 | elapsed:   34.3s remaining:    4.2s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:   38.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(learning_rate=0.1, n_estimators=300)\n",
      "Train Accuracy: 67.76038531005419 %\n",
      "Test Accuracy: 67.16203559163284 %\n",
      "====================================================================\n",
      "Confusion matrix: \n",
      " [[ 321    0    0 1617  129   33    0    0]\n",
      " [   0 1800    0    0    0    0    0    0]\n",
      " [   0    0 2101    0    0    0    0    0]\n",
      " [  67    0    0  909 1030   90    0    0]\n",
      " [   0    0    0  104 1893    0    0    0]\n",
      " [ 237    0    0  559 1148   20    0    0]\n",
      " [   2    0    0    1  166    0 1690   14]\n",
      " [   0    0    0    0   62    0    0 2022]]\n",
      "====================================================================\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.5120    0.1529    0.2354      2100\n",
      "           1     1.0000    1.0000    1.0000      1800\n",
      "           2     1.0000    1.0000    1.0000      2101\n",
      "           3     0.2850    0.4337    0.3439      2096\n",
      "           4     0.4275    0.9479    0.5893      1997\n",
      "           5     0.1399    0.0102    0.0190      1964\n",
      "           6     1.0000    0.9023    0.9486      1873\n",
      "           7     0.9931    0.9702    0.9816      2084\n",
      "\n",
      "    accuracy                         0.6716     16015\n",
      "   macro avg     0.6697    0.6771    0.6397     16015\n",
      "weighted avg     0.6647    0.6716    0.6339     16015\n",
      "\n",
      "====================================================================\n"
     ]
    }
   ],
   "source": [
    "## 1. KNN MODEL\n",
    "\n",
    "print(\"KNN MODEL:\")\n",
    "\n",
    "k = [i for i in range(2,10)]\n",
    "p = [j for j in range(1,3)]\n",
    "param_grid = [{'n_neighbors': k, 'p': p}]\n",
    "knn_grid_search = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=3,\n",
    "                           scoring='f1_weighted', n_jobs=-1, return_train_score=True,\n",
    "                           verbose=1)\n",
    "\n",
    "knn_grid_search.fit(X_trn_scaled_, y_trn_)\n",
    "knn_clf = knn_grid_search.best_estimator_\n",
    "print(knn_clf)\n",
    "\n",
    "print(\"Train Accuracy:\", 100*knn_clf.score(X_trn_scaled_, y_trn_), chr(37))\n",
    "print(\"Test Accuracy:\", 100*knn_clf.score(X_tst_scaled_, y_tst_), chr(37))\n",
    "\n",
    "y_tst_pred_ = knn_clf.predict(X_tst_scaled_)\n",
    "print(\"====================================================================\")\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_tst_, y_tst_pred_))\n",
    "print(\"====================================================================\")\n",
    "print(\"Classification report: \\n\", classification_report(y_tst_, y_tst_pred_, digits=4))\n",
    "print(\"====================================================================\")\n",
    "\n",
    "\n",
    "## 2. SVM MODEL\n",
    "\n",
    "print(\"SVM MODEL:\")\n",
    "\n",
    "C = [2**i for i in range(0, 4)]\n",
    "gamma = [2**j for j in range(-2,2)]\n",
    "param_grid = [{'C': C, 'gamma': gamma}]\n",
    "svm_grid_search = GridSearchCV(SVC(), param_grid=param_grid, cv=3,\n",
    "                           scoring='f1_weighted', n_jobs=-1, return_train_score=True,\n",
    "                           verbose=1)\n",
    "svm_grid_search.fit(X_trn_scaled_, y_trn_)\n",
    "svm_clf = svm_grid_search.best_estimator_\n",
    "print(svm_clf)\n",
    "\n",
    "print(\"Train Accuracy:\", 100*svm_clf.score(X_trn_scaled_, y_trn_), chr(37))\n",
    "print(\"Test Accuracy:\", 100*svm_clf.score(X_tst_scaled_, y_tst_), chr(37))\n",
    "\n",
    "y_tst_pred_ = svm_clf.predict(X_tst_scaled_)\n",
    "print(\"====================================================================\")\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_tst_, y_tst_pred_))\n",
    "print(\"====================================================================\")\n",
    "print(\"Classification report: \\n\", classification_report(y_tst_, y_tst_pred_, digits=4))\n",
    "print(\"====================================================================\")\n",
    "\n",
    "## 3. RANDOM FOREST MODEL\n",
    "\n",
    "print(\"RANDOM FOREST MODEL:\")\n",
    "\n",
    "n_estimators_ = [int(x) for x in np.linspace(100, 550, 10)]\n",
    "\n",
    "param_grid = {'n_estimators':n_estimators_}\n",
    "rf_grid_search = GridSearchCV(RandomForestClassifier(), param_grid=param_grid, cv=3,\n",
    "                              scoring='f1_weighted', n_jobs=-1, return_train_score=True,\n",
    "                              verbose=1)\n",
    "rf_grid_search.fit(X_trn_, y_trn_)\n",
    "\n",
    "rf_clf = rf_grid_search.best_estimator_\n",
    "\n",
    "print(rf_clf)\n",
    "\n",
    "print(\"Train Accuracy:\", 100*rf_clf.score(X_trn_, y_trn_), chr(37))\n",
    "print(\"Test Accuracy:\", 100*rf_clf.score(X_tst_, y_tst_), chr(37))\n",
    "\n",
    "y_tst_pred_ = rf_clf.predict(X_tst_)\n",
    "print(\"====================================================================\")\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_tst_, y_tst_pred_))\n",
    "print(\"====================================================================\")\n",
    "print(\"Classification report: \\n\", classification_report(y_tst_, y_tst_pred_, digits=4))\n",
    "print(\"====================================================================\")\n",
    "\n",
    "\n",
    "# ## 4. LOGISTIC REGRESSION MODEL\n",
    "\n",
    "# C= np.logspace(-4,4,9)\n",
    "# solver=['newton-cg']\n",
    "\n",
    "# param_grid = [{'solver': solver, 'C': C}]\n",
    "# lr_grid_search = GridSearchCV(LogisticRegression(max_iter=100),\n",
    "#                            param_grid=param_grid, cv=3, scoring='f1_weighted',\n",
    "#                            n_jobs=-1, return_train_score=True, verbose=1)\n",
    "# lr_grid_search.fit(X_trn_scaled_, y_trn_)\n",
    "# lr_clf = lr_grid_search.best_estimator_\n",
    "# print(lr_clf)\n",
    "\n",
    "# print(\"Train Accuracy:\", 100*lr_clf.score(X_trn_scaled_, y_trn_), chr(37))\n",
    "# print(\"Test Accuracy:\", 100*lr_clf.score(X_tst_scaled_, y_tst_), chr(37))\n",
    "\n",
    "## 5. ADABOOST MODEL\n",
    "\n",
    "print(\"ADABOOST MODEL:\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators' : [100, 200, 300],\n",
    "    'learning_rate' : [0.001, 0.01, 0.1]\n",
    "}\n",
    "ad_grid_search = GridSearchCV(AdaBoostClassifier(), param_grid = param_grid,\n",
    "                                cv=3, scoring='f1_weighted', n_jobs=-1, return_train_score=True, verbose=1\n",
    "                                )\n",
    "ad_grid_search.fit(X_trn_, y_trn_)\n",
    "\n",
    "ad_clf = ad_grid_search.best_estimator_\n",
    "\n",
    "print(ad_clf)\n",
    "\n",
    "print(\"Train Accuracy:\", 100*ad_clf.score(X_trn_, y_trn_), chr(37))\n",
    "print(\"Test Accuracy:\", 100*ad_clf.score(X_tst_, y_tst_), chr(37))\n",
    "\n",
    "y_tst_pred_ = ad_clf.predict(X_tst_)\n",
    "print(\"====================================================================\")\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_tst_, y_tst_pred_))\n",
    "print(\"====================================================================\")\n",
    "print(\"Classification report: \\n\", classification_report(y_tst_, y_tst_pred_, digits=4))\n",
    "print(\"====================================================================\")\n",
    "\n",
    "\n",
    "# ## 6. GAUSIAN NAIVE BAYSESSIAN\n",
    "\n",
    "# params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "# gnb_grid_search = GridSearchCV(GaussianNB(), param_grid=params_NB, cv=3, scoring='accuracy',return_train_score=True)\n",
    "# gnb_grid_search.fit(X_trn_scaled_, y_trn_)\n",
    "\n",
    "# gnb_clf = gnb_grid_search.best_estimator_\n",
    "\n",
    "# print(gnb_clf)\n",
    "\n",
    "# print(\"Train Accuracy:\", 100*gnb_clf.score(X_trn_scaled_, y_trn_), chr(37))\n",
    "# print(\"Test Accuracy:\", 100*gnb_clf.score(X_tst_scaled_, y_tst_), chr(37))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 - GPU",
   "language": "python",
   "name": "tf-gpu"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
