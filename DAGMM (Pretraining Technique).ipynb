{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
    "from dnn_INSE_6180 import DNN\n",
    "from dagmm_INSE_6180 import DAGMM\n",
    "from sae_INSE_6180 import SAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = './datasets/chiller/df_dataset/'\n",
    "\n",
    "def load_data(load_path, filename):\n",
    "    csv_load_path = os.path.join(load_path, filename)\n",
    "    return pd.read_csv(csv_load_path)\n",
    "\n",
    "data = load_data(load_path, 'chiller10.csv') # Chiller data of Severity Level 1\n",
    "data = data.drop('Unnamed: 0', axis='columns')\n",
    "data_trn, data_tst = train_test_split(data, test_size=0.5, random_state=0)\n",
    "X_trn, y_trn = data_trn.iloc[:, :-1], data_trn.iloc[:, -1]\n",
    "X_tst, y_tst = data_tst.iloc[:, :-1], data_tst.iloc[:, -1]\n",
    "scaler = StandardScaler().fit(X_trn)\n",
    "X_trn_scaled, X_tst_scaled = scaler.transform(X_trn), scaler.transform(X_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset 1 - 10% of Origninal data\n",
    "data_trn_sub, _ = train_test_split(data_trn, test_size=0.9, random_state=0)\n",
    "X_trn_d1, y_trn_d1 = data_trn_sub.iloc[:, :-1], data_trn_sub.iloc[:, -1]\n",
    "\n",
    "# Scaling data\n",
    "X_trn_scaled_d1 = scaler.transform(X_trn_d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset 2 - 3% of Origninal training data\n",
    "data_trn_sub, _ = train_test_split(data_trn, test_size=0.97, random_state=0)\n",
    "X_trn_d2, y_trn_d2 = data_trn_sub.iloc[:, :-1], data_trn_sub.iloc[:, -1]\n",
    "\n",
    "# Scaling data\n",
    "X_trn_scaled_d2 = scaler.transform(X_trn_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset 3 - 1% of Origninal training data\n",
    "data_trn_sub, _ = train_test_split(data_trn, test_size=0.99, random_state=0)\n",
    "X_trn_d3, y_trn_d3 = data_trn_sub.iloc[:, :-1], data_trn_sub.iloc[:, -1]\n",
    "\n",
    "# Scaling data\n",
    "X_trn_scaled_d3 = scaler.transform(X_trn_d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset 4 - 0.5% of Origninal data\n",
    "data_trn_sub, _ = train_test_split(data_trn, test_size=0.995, random_state=0)\n",
    "X_trn_d4, y_trn_d4 = data_trn_sub.iloc[:, :-1], data_trn_sub.iloc[:, -1]\n",
    "\n",
    "# Scaling data\n",
    "X_trn_scaled_d4 = scaler.transform(X_trn_d4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207, 65)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# # Dataset 1 - 10% of Original dataset\n",
    "# X_trn_, X_tst_ = X_trn_d1, X_tst\n",
    "# X_trn_scaled_, X_tst_scaled_ = X_trn_scaled_d1, X_tst_scaled\n",
    "# y_trn_, y_tst_ = y_trn_d1, y_tst\n",
    "\n",
    "# # Dataset 2 - 3% of Origninal data\n",
    "# X_trn_, X_tst_ = X_trn_d2, X_tst\n",
    "# X_trn_scaled_, X_tst_scaled_ = X_trn_scaled_d2, X_tst_scaled\n",
    "# y_trn_, y_tst_ = y_trn_d2, y_tst\n",
    "\n",
    "## Dataset 3 - 1% of Origninal data\n",
    "X_trn_, X_tst_ = X_trn_d3, X_tst\n",
    "X_trn_scaled_, X_tst_scaled_ = X_trn_scaled_d3, X_tst_scaled\n",
    "y_trn_, y_tst_ = y_trn_d3, y_tst\n",
    "\n",
    "# ## Dataset 4 - 0.5% of Origninal data\n",
    "# X_trn_, X_tst_ = X_trn_d4, X_tst\n",
    "# X_trn_scaled_, X_tst_scaled_ = X_trn_scaled_d4, X_tst_scaled\n",
    "# y_trn_, y_tst_ = y_trn_d4, y_tst\n",
    "\n",
    "X_trn_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pretrained model SAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "561/584 [===========================>..] - ETA: 0s - loss: 5.4532WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'tuple'> input: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 65) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 65) dtype=float32>)\n",
      "Consider rewriting this model with the Functional API.\n",
      "584/584 [==============================] - 3s 2ms/step - loss: 5.3760 - val_loss: 1.0639\n",
      "Epoch 2/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.9880 - val_loss: 0.2993\n",
      "Epoch 3/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.5112 - val_loss: 0.1989\n",
      "Epoch 4/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.4157 - val_loss: 0.1771\n",
      "Epoch 5/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3695 - val_loss: 0.1711\n",
      "Epoch 6/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.4212 - val_loss: 0.1602\n",
      "Epoch 7/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.3934 - val_loss: 0.1540\n",
      "Epoch 8/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.3214 - val_loss: 0.1547\n",
      "Epoch 9/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.3138 - val_loss: 0.1541\n",
      "Epoch 10/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.3184 - val_loss: 0.1420\n",
      "Epoch 11/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.3630 - val_loss: 0.1432\n",
      "Epoch 12/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.3369 - val_loss: 0.1395\n",
      "Epoch 13/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.3580 - val_loss: 0.1374\n",
      "Epoch 14/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.3073 - val_loss: 0.1361\n",
      "Epoch 15/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3231 - val_loss: 0.1380\n",
      "Epoch 16/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.3028 - val_loss: 0.1419\n",
      "Epoch 17/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.3724 - val_loss: 0.1343\n",
      "Epoch 18/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.3152 - val_loss: 0.1342\n",
      "Epoch 19/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.3079 - val_loss: 0.1431\n",
      "Epoch 20/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.3230 - val_loss: 0.1316\n",
      "Epoch 21/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.3019 - val_loss: 0.1302\n",
      "Epoch 22/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.2845 - val_loss: 0.1280\n",
      "Epoch 23/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.3029 - val_loss: 0.1262\n",
      "Epoch 24/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.3080 - val_loss: 0.1341\n",
      "Epoch 25/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.2726 - val_loss: 0.1254\n",
      "Epoch 26/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.2873 - val_loss: 0.1394\n",
      "Epoch 27/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3452 - val_loss: 0.1219\n",
      "Epoch 28/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.2695 - val_loss: 0.1253\n",
      "Epoch 29/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.2642 - val_loss: 0.1309\n",
      "Epoch 30/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.2815 - val_loss: 0.1267\n",
      "Epoch 31/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.3016 - val_loss: 0.1195\n",
      "Epoch 32/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.2687 - val_loss: 0.1236\n",
      "Epoch 33/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.2805 - val_loss: 0.1221\n",
      "Epoch 34/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.2595 - val_loss: 0.1231\n",
      "Epoch 35/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.2897 - val_loss: 0.1181\n",
      "Epoch 36/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.2672 - val_loss: 0.1236\n",
      "Epoch 37/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.2685 - val_loss: 0.1173\n",
      "Epoch 38/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.2838 - val_loss: 0.1172\n",
      "Epoch 39/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.2722 - val_loss: 0.1193\n",
      "Epoch 40/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.2492 - val_loss: 0.1343\n",
      "Epoch 41/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.2808 - val_loss: 0.1169\n",
      "Epoch 42/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.2529 - val_loss: 0.1141\n",
      "Epoch 43/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.2889 - val_loss: 0.1135\n",
      "Epoch 44/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.2702 - val_loss: 0.1112\n",
      "Epoch 45/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.2972 - val_loss: 0.1133\n",
      "Epoch 46/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.2515 - val_loss: 0.1217\n",
      "Epoch 47/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.2648 - val_loss: 0.1147\n",
      "Epoch 48/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.2930 - val_loss: 0.1111\n",
      "Epoch 49/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.2945 - val_loss: 0.1148\n",
      "Epoch 50/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.2675 - val_loss: 0.1083\n",
      "Epoch 51/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.2592 - val_loss: 0.1102\n",
      "Epoch 52/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.2393 - val_loss: 0.1114\n",
      "Epoch 53/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.2818 - val_loss: 0.1124\n",
      "Epoch 54/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.2593 - val_loss: 0.1143\n",
      "Epoch 55/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.2442 - val_loss: 0.1083\n"
     ]
    }
   ],
   "source": [
    "# Pretrain use SAE\n",
    "\n",
    "out_dir = './results/'\n",
    "model_sae = SAE(sae_hiddens=[100, 50, 20], out_directory = out_dir, dropout_rate=0, n_epochs=100, normalize=True)\n",
    "model_sae.build_model(X_trn)\n",
    "model_sae.fit(X_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "20764/20764 [==============================] - mean_loss: 67.8919 - val_loss: 20.5215\n",
      "Best Epoch: 1\n",
      "Epoch 2/30\n",
      "20764/20764 [==============================] - mean_loss: 23.9866 - val_loss: 17.4089\n",
      "Best Epoch: 2\n",
      "Epoch 3/30\n",
      "20764/20764 [==============================] - mean_loss: 18.5375 - val_loss: 9.6504\n",
      "Best Epoch: 3\n",
      "Epoch 4/30\n",
      "20764/20764 [==============================] - mean_loss: 15.3123 - val_loss: 7.6337\n",
      "Best Epoch: 4\n",
      "Epoch 5/30\n",
      "20764/20764 [==============================] - mean_loss: 15.7448 - val_loss: 7.4796\n",
      "Best Epoch: 5\n",
      "Epoch 6/30\n",
      "20764/20764 [==============================] - mean_loss: 13.5706 - val_loss: 5.4169\n",
      "Best Epoch: 6\n",
      "Epoch 7/30\n",
      "20764/20764 [==============================] - mean_loss: 11.2384 - val_loss: 5.0528\n",
      "Best Epoch: 7\n",
      "Epoch 8/30\n",
      "20764/20764 [==============================] - mean_loss: 11.8342 - val_loss: 6.7745\n",
      "Best Epoch: 7\n",
      "Epoch 9/30\n",
      "20764/20764 [==============================] - mean_loss: 11.2503 - val_loss: 3.8981\n",
      "Best Epoch: 9\n",
      "Epoch 10/30\n",
      "20764/20764 [==============================] - mean_loss: 11.5816 - val_loss: 9.3650\n",
      "Best Epoch: 9\n",
      "Epoch 11/30\n",
      "20764/20764 [==============================] - mean_loss: 12.0452 - val_loss: 3.1884\n",
      "Best Epoch: 11\n",
      "Epoch 12/30\n",
      "20764/20764 [==============================] - mean_loss: 9.3204 - val_loss: 3.8113\n",
      "Best Epoch: 11\n",
      "Epoch 13/30\n",
      "20764/20764 [==============================] - mean_loss: 12.6739 - val_loss: 3.3150\n",
      "Best Epoch: 11\n",
      "Epoch 14/30\n",
      "20764/20764 [==============================] - mean_loss: 8.7881 - val_loss: 3.0640\n",
      "Best Epoch: 14\n",
      "Epoch 15/30\n",
      "20764/20764 [==============================] - mean_loss: 10.5728 - val_loss: 4.5769\n",
      "Best Epoch: 14\n",
      "Epoch 16/30\n",
      "20764/20764 [==============================] - mean_loss: 8.8131 - val_loss: 2.0212\n",
      "Best Epoch: 16\n",
      "Epoch 17/30\n",
      "20764/20764 [==============================] - mean_loss: 9.4317 - val_loss: 5.4429\n",
      "Best Epoch: 16\n",
      "Epoch 18/30\n",
      "20764/20764 [==============================] - mean_loss: 6.8919 - val_loss: 2.1890\n",
      "Best Epoch: 16\n",
      "Epoch 19/30\n",
      "20764/20764 [==============================] - mean_loss: 8.2098 - val_loss: 2.1647\n",
      "Best Epoch: 16\n",
      "Epoch 20/30\n",
      "20764/20764 [==============================] - mean_loss: 6.5573 - val_loss: 1.9149\n",
      "Best Epoch: 20\n",
      "Epoch 21/30\n",
      "20764/20764 [==============================] - mean_loss: 7.4305 - val_loss: 3.9284\n",
      "Best Epoch: 20\n",
      "Epoch 22/30\n",
      "20764/20764 [==============================] - mean_loss: 8.2941 - val_loss: 1.6097\n",
      "Best Epoch: 22\n",
      "Epoch 23/30\n",
      "20764/20764 [==============================] - mean_loss: 7.5922 - val_loss: 2.8671\n",
      "Best Epoch: 22\n",
      "Epoch 24/30\n",
      "20764/20764 [==============================] - mean_loss: 6.3445 - val_loss: 1.6056\n",
      "Best Epoch: 24\n",
      "Epoch 25/30\n",
      "20764/20764 [==============================] - mean_loss: 7.2119 - val_loss: 1.2766\n",
      "Best Epoch: 25\n",
      "Epoch 26/30\n",
      "20764/20764 [==============================] - mean_loss: 9.2485 - val_loss: 6.1272\n",
      "Best Epoch: 25\n",
      "Epoch 27/30\n",
      "20764/20764 [==============================] - mean_loss: 6.4428 - val_loss: 1.8098\n",
      "Best Epoch: 25\n",
      "Epoch 28/30\n",
      "20764/20764 [==============================] - mean_loss: 5.4573 - val_loss: 1.2065\n",
      "Best Epoch: 28\n",
      "Epoch 29/30\n",
      "20764/20764 [==============================] - mean_loss: 6.4997 - val_loss: 1.6473\n",
      "Best Epoch: 28\n",
      "Epoch 30/30\n",
      "20764/20764 [==============================] - mean_loss: 6.2689 - val_loss: 3.6842\n",
      "Best Epoch: 28\n"
     ]
    }
   ],
   "source": [
    "# Pretrain using DAGMM\n",
    "out_dir = './results/'\n",
    "model_dagmm = DAGMM(comp_hiddens=[100, 50, 20], comp_activation=\"elu\",\n",
    "                    est_hiddens=[10, 3], est_activation=\"elu\", est_dropout_ratio=0.1,\n",
    "                    n_epochs=30, batch_size=1024, normalize=True)\n",
    "model_dagmm.build(X_trn)\n",
    "model_dagmm.fit(X_trn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN models with and without pretrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 48ms/step - loss: 2.2249 - accuracy: 0.1731 - val_loss: 1.9799 - val_accuracy: 0.2619\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.2192 - accuracy: 0.1550 - val_loss: 1.9785 - val_accuracy: 0.2619\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2340 - accuracy: 0.1560 - val_loss: 1.9773 - val_accuracy: 0.2619\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2038 - accuracy: 0.1502 - val_loss: 1.9754 - val_accuracy: 0.2619\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2278 - accuracy: 0.1277 - val_loss: 1.9747 - val_accuracy: 0.2619\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.1988 - accuracy: 0.1439 - val_loss: 1.9745 - val_accuracy: 0.2857\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.2206 - accuracy: 0.0883 - val_loss: 1.9739 - val_accuracy: 0.2619\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.1543 - accuracy: 0.1377 - val_loss: 1.9739 - val_accuracy: 0.2619\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.2075 - accuracy: 0.1084 - val_loss: 1.9741 - val_accuracy: 0.2619\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.1512 - accuracy: 0.1305 - val_loss: 1.9747 - val_accuracy: 0.2619\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - 1s 70ms/step - loss: 2.1278 - accuracy: 0.1705 - val_loss: 1.9582 - val_accuracy: 0.1905\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0595 - accuracy: 0.1286 - val_loss: 1.9508 - val_accuracy: 0.2619\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.9810 - accuracy: 0.2845 - val_loss: 1.9380 - val_accuracy: 0.2857\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.8989 - accuracy: 0.3158 - val_loss: 1.9181 - val_accuracy: 0.3571\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.8460 - accuracy: 0.3248 - val_loss: 1.8266 - val_accuracy: 0.3810\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.7525 - accuracy: 0.3343 - val_loss: 1.7131 - val_accuracy: 0.4048\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6651 - accuracy: 0.3910 - val_loss: 1.5600 - val_accuracy: 0.4524\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.5600 - accuracy: 0.4175 - val_loss: 1.5569 - val_accuracy: 0.4762\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.4602 - accuracy: 0.4338 - val_loss: 1.3763 - val_accuracy: 0.4286\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.3622 - accuracy: 0.5139 - val_loss: 1.4218 - val_accuracy: 0.5000\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.2987 - accuracy: 0.4775 - val_loss: 1.2035 - val_accuracy: 0.5952\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1821 - accuracy: 0.5428 - val_loss: 1.1927 - val_accuracy: 0.5714\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1766 - accuracy: 0.5269 - val_loss: 1.1193 - val_accuracy: 0.6190\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.1167 - accuracy: 0.6138 - val_loss: 1.0738 - val_accuracy: 0.6429\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.0680 - accuracy: 0.6382 - val_loss: 1.0214 - val_accuracy: 0.6667\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.0294 - accuracy: 0.6567 - val_loss: 0.9186 - val_accuracy: 0.6667\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.9689 - accuracy: 0.6167 - val_loss: 0.8886 - val_accuracy: 0.6667\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.9251 - accuracy: 0.7011 - val_loss: 0.8259 - val_accuracy: 0.6905\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8874 - accuracy: 0.7005 - val_loss: 0.7862 - val_accuracy: 0.7143\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8559 - accuracy: 0.6669 - val_loss: 0.7442 - val_accuracy: 0.7381\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7322 - accuracy: 0.7263 - val_loss: 0.7191 - val_accuracy: 0.7143\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7580 - accuracy: 0.7345 - val_loss: 0.6657 - val_accuracy: 0.7619\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7220 - accuracy: 0.7296 - val_loss: 0.6232 - val_accuracy: 0.7619\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5876 - accuracy: 0.8200 - val_loss: 0.5791 - val_accuracy: 0.8810\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6081 - accuracy: 0.8138 - val_loss: 0.5540 - val_accuracy: 0.8095\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6072 - accuracy: 0.8261 - val_loss: 0.4608 - val_accuracy: 0.8333\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5756 - accuracy: 0.8100 - val_loss: 0.4441 - val_accuracy: 0.8095\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5621 - accuracy: 0.8531 - val_loss: 0.4156 - val_accuracy: 0.8571\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5103 - accuracy: 0.8477 - val_loss: 0.3782 - val_accuracy: 0.8571\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5117 - accuracy: 0.8475 - val_loss: 0.3958 - val_accuracy: 0.8810\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4903 - accuracy: 0.8312 - val_loss: 0.3532 - val_accuracy: 0.9048\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4462 - accuracy: 0.8244 - val_loss: 0.3378 - val_accuracy: 0.9286\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3953 - accuracy: 0.8757 - val_loss: 0.3356 - val_accuracy: 0.9286\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3745 - accuracy: 0.8649 - val_loss: 0.2987 - val_accuracy: 0.9286\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3805 - accuracy: 0.8741 - val_loss: 0.3548 - val_accuracy: 0.8810\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3717 - accuracy: 0.8560 - val_loss: 0.2771 - val_accuracy: 0.9286\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3431 - accuracy: 0.8557 - val_loss: 0.2824 - val_accuracy: 0.9286\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3666 - accuracy: 0.8822 - val_loss: 0.3665 - val_accuracy: 0.9524\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3825 - accuracy: 0.8692 - val_loss: 0.2883 - val_accuracy: 0.9524\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3796 - accuracy: 0.8601 - val_loss: 0.2565 - val_accuracy: 0.9048\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2815 - accuracy: 0.9083 - val_loss: 0.5181 - val_accuracy: 0.7857\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4327 - accuracy: 0.8104 - val_loss: 0.2836 - val_accuracy: 0.9286\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2852 - accuracy: 0.9212 - val_loss: 0.2409 - val_accuracy: 0.9524\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3039 - accuracy: 0.8875 - val_loss: 0.4000 - val_accuracy: 0.9286\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3588 - accuracy: 0.8847 - val_loss: 0.2572 - val_accuracy: 0.9286\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2342 - accuracy: 0.9307 - val_loss: 0.2597 - val_accuracy: 0.9048\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3141 - accuracy: 0.8800 - val_loss: 0.2416 - val_accuracy: 0.9286\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2626 - accuracy: 0.8834 - val_loss: 0.2509 - val_accuracy: 0.9048\n",
      "DNN accuracy: 0.90\n",
      "Training accuracry: 90.34%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN accuracy: 0.80\n",
      "Test accuracry: 80.49%\n",
      "====================================================================\n",
      "Confusion matrix: \n",
      " [[1766    0   26  609   81   49   44    3]\n",
      " [   7 2531   33   12    0    1    0    2]\n",
      " [   1    0 2574    1    0    0    0    0]\n",
      " [ 471    0   17 1014  486  550   23    0]\n",
      " [  40    0   24  313 2156  108    2   11]\n",
      " [ 371    0   26  532  100 1558    3    0]\n",
      " [   3    2   24   17    2    1 2580   16]\n",
      " [   2    0   17   12    2    0    7 2534]]\n",
      "====================================================================\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6637    0.6850    0.6742      2578\n",
      "           1     0.9992    0.9787    0.9889      2586\n",
      "           2     0.9391    0.9992    0.9682      2576\n",
      "           3     0.4040    0.3959    0.3999      2561\n",
      "           4     0.7626    0.8124    0.7867      2654\n",
      "           5     0.6873    0.6015    0.6415      2590\n",
      "           6     0.9703    0.9754    0.9729      2645\n",
      "           7     0.9875    0.9845    0.9860      2574\n",
      "\n",
      "    accuracy                         0.8049     20764\n",
      "   macro avg     0.8017    0.8041    0.8023     20764\n",
      "weighted avg     0.8024    0.8049    0.8030     20764\n",
      "\n",
      "====================================================================\n"
     ]
    }
   ],
   "source": [
    "# Using SAE to pretrain\n",
    "\n",
    "sae_model = model_sae.restore()\n",
    "\n",
    "DNN_classifier = DNN(dnn_hiddens=[100, 50, 20], output_size=8, out_directory=out_dir,\n",
    "                     pretrained_model=sae_model, normalize=True, rate=0, n_epochs=100, pretrain_sae=True, \n",
    "                     pretrain_dagmm=False, monte_carlo=True)\n",
    "DNN_classifier.build_model(X_trn_)\n",
    "DNN_classifier.fit((X_trn_, y_trn_))\n",
    "\n",
    "print(\"Training accuracry: %.2f%%\" %(100*DNN_classifier.score((X_trn_, y_trn_))))\n",
    "print(\"Test accuracry: %.2f%%\" %(100*DNN_classifier.score((X_tst_, y_tst_))))\n",
    "\n",
    "y_tst_pred_ = DNN_classifier.predict(X_tst_)\n",
    "print(\"====================================================================\")\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_tst_, y_tst_pred_))\n",
    "print(\"====================================================================\")\n",
    "print(\"Classification report: \\n\", classification_report(y_tst_, y_tst_pred_, digits=4))\n",
    "print(\"====================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 47ms/step - loss: 2.1725 - accuracy: 0.1867 - val_loss: 2.0972 - val_accuracy: 0.2381\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1430 - accuracy: 0.1784 - val_loss: 2.0894 - val_accuracy: 0.2381\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.0795 - accuracy: 0.2246 - val_loss: 2.0809 - val_accuracy: 0.2381\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1213 - accuracy: 0.2018 - val_loss: 2.0723 - val_accuracy: 0.2381\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.1204 - accuracy: 0.2184 - val_loss: 2.0651 - val_accuracy: 0.2381\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.1261 - accuracy: 0.1931 - val_loss: 2.0572 - val_accuracy: 0.2381\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.1145 - accuracy: 0.2120 - val_loss: 2.0489 - val_accuracy: 0.2619\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.1271 - accuracy: 0.1893 - val_loss: 2.0409 - val_accuracy: 0.2619\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0685 - accuracy: 0.2415 - val_loss: 2.0335 - val_accuracy: 0.2619\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0332 - accuracy: 0.2478 - val_loss: 2.0266 - val_accuracy: 0.2619\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - 1s 46ms/step - loss: 2.0354 - accuracy: 0.2436 - val_loss: 1.8682 - val_accuracy: 0.3571\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 34ms/step - loss: 1.8390 - accuracy: 0.3810 - val_loss: 1.7264 - val_accuracy: 0.4286\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.6282 - accuracy: 0.5155 - val_loss: 1.6136 - val_accuracy: 0.5238\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.5247 - accuracy: 0.5970 - val_loss: 1.4875 - val_accuracy: 0.6667\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.3773 - accuracy: 0.7159 - val_loss: 1.3768 - val_accuracy: 0.6905\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.2647 - accuracy: 0.7463 - val_loss: 1.2638 - val_accuracy: 0.6667\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.1733 - accuracy: 0.7487 - val_loss: 1.1345 - val_accuracy: 0.6905\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.0740 - accuracy: 0.7736 - val_loss: 1.0398 - val_accuracy: 0.7857\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.9176 - accuracy: 0.8355 - val_loss: 0.9477 - val_accuracy: 0.8095\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8855 - accuracy: 0.8098 - val_loss: 0.8612 - val_accuracy: 0.7857\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.7410 - accuracy: 0.8512 - val_loss: 0.8077 - val_accuracy: 0.8095\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6889 - accuracy: 0.8795 - val_loss: 0.7620 - val_accuracy: 0.8333\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6764 - accuracy: 0.8838 - val_loss: 0.6962 - val_accuracy: 0.8571\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6038 - accuracy: 0.8690 - val_loss: 0.6529 - val_accuracy: 0.7857\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5821 - accuracy: 0.9007 - val_loss: 0.6108 - val_accuracy: 0.8095\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5554 - accuracy: 0.8759 - val_loss: 0.5547 - val_accuracy: 0.9048\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4711 - accuracy: 0.9061 - val_loss: 0.5305 - val_accuracy: 0.9048\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4585 - accuracy: 0.9040 - val_loss: 0.4774 - val_accuracy: 0.9048\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4247 - accuracy: 0.9083 - val_loss: 0.4434 - val_accuracy: 0.8810\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.4390 - accuracy: 0.9168 - val_loss: 0.4143 - val_accuracy: 0.8810\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3567 - accuracy: 0.9082 - val_loss: 0.3924 - val_accuracy: 0.8810\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3652 - accuracy: 0.8949 - val_loss: 0.3783 - val_accuracy: 0.9286\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3892 - accuracy: 0.8789 - val_loss: 0.3635 - val_accuracy: 0.8810\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2877 - accuracy: 0.9486 - val_loss: 0.3422 - val_accuracy: 0.8810\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3293 - accuracy: 0.9138 - val_loss: 0.3510 - val_accuracy: 0.9286\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3196 - accuracy: 0.9310 - val_loss: 0.3306 - val_accuracy: 0.9048\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3224 - accuracy: 0.9065 - val_loss: 0.3096 - val_accuracy: 0.8810\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2890 - accuracy: 0.9146 - val_loss: 0.3040 - val_accuracy: 0.8810\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2669 - accuracy: 0.9369 - val_loss: 0.2941 - val_accuracy: 0.9048\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2895 - accuracy: 0.9296 - val_loss: 0.2769 - val_accuracy: 0.9048\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2512 - accuracy: 0.9406 - val_loss: 0.2690 - val_accuracy: 0.9286\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2240 - accuracy: 0.9429 - val_loss: 0.2826 - val_accuracy: 0.9286\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2151 - accuracy: 0.9552 - val_loss: 0.2902 - val_accuracy: 0.8810\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1974 - accuracy: 0.9794 - val_loss: 0.2844 - val_accuracy: 0.8810\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1834 - accuracy: 0.9662 - val_loss: 0.3115 - val_accuracy: 0.9048\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2227 - accuracy: 0.9388 - val_loss: 0.2630 - val_accuracy: 0.9048\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1947 - accuracy: 0.9332 - val_loss: 0.2659 - val_accuracy: 0.8810\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1836 - accuracy: 0.9572 - val_loss: 0.3281 - val_accuracy: 0.8571\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2223 - accuracy: 0.9211 - val_loss: 0.2512 - val_accuracy: 0.8810\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2317 - accuracy: 0.9071 - val_loss: 0.2558 - val_accuracy: 0.9048\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1767 - accuracy: 0.9513 - val_loss: 0.3375 - val_accuracy: 0.8810\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2139 - accuracy: 0.9628 - val_loss: 0.2881 - val_accuracy: 0.9048\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1725 - accuracy: 0.9645 - val_loss: 0.2503 - val_accuracy: 0.9048\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1708 - accuracy: 0.9591 - val_loss: 0.2705 - val_accuracy: 0.9048\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1663 - accuracy: 0.9649 - val_loss: 0.2774 - val_accuracy: 0.9048\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1288 - accuracy: 0.9873 - val_loss: 0.2595 - val_accuracy: 0.9048\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1491 - accuracy: 0.9590 - val_loss: 0.2740 - val_accuracy: 0.9286\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.1522 - accuracy: 0.9508 - val_loss: 0.2665 - val_accuracy: 0.9286\n",
      "DNN accuracy: 0.95\n",
      "Training accuracry: 94.69%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DNN accuracy: 0.84\n",
      "Test accuracry: 84.24%\n",
      "====================================================================\n",
      "Confusion matrix: \n",
      " [[1844    1   16  579   58   73    7    0]\n",
      " [   0 2546   12    7    0   21    0    0]\n",
      " [   0    0 2532   21    0   23    0    0]\n",
      " [ 463    0   10 1236  424  424    4    0]\n",
      " [  33    3   14  227 2207  152    4   14]\n",
      " [ 199    0   17  215  122 2037    0    0]\n",
      " [   2    1   17   18    1   15 2588    3]\n",
      " [   0    0   17   14   34    7    1 2501]]\n",
      "====================================================================\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7257    0.7153    0.7205      2578\n",
      "           1     0.9980    0.9845    0.9912      2586\n",
      "           2     0.9609    0.9829    0.9718      2576\n",
      "           3     0.5334    0.4826    0.5068      2561\n",
      "           4     0.7755    0.8316    0.8025      2654\n",
      "           5     0.7402    0.7865    0.7626      2590\n",
      "           6     0.9939    0.9784    0.9861      2645\n",
      "           7     0.9932    0.9716    0.9823      2574\n",
      "\n",
      "    accuracy                         0.8424     20764\n",
      "   macro avg     0.8401    0.8417    0.8405     20764\n",
      "weighted avg     0.8406    0.8424    0.8411     20764\n",
      "\n",
      "====================================================================\n"
     ]
    }
   ],
   "source": [
    "# Using DAGMM to pretrain\n",
    "\n",
    "dagmm_model = model_dagmm.restore()\n",
    "out_dir = './results/'\n",
    "DNN_classifier = DNN(dnn_hiddens=[100, 50, 20], output_size=8, out_directory=out_dir,\n",
    "                     pretrained_model=dagmm_model, normalize=True, rate=0, n_epochs=100, pretrain_sae=False,\n",
    "                     pretrain_dagmm=True, monte_carlo=True)\n",
    "DNN_classifier.build_model(X_trn_)\n",
    "DNN_classifier.fit((X_trn_, y_trn_))\n",
    "\n",
    "print(\"Training accuracry: %.2f%%\" %(100*DNN_classifier.score((X_trn_, y_trn_))))\n",
    "print(\"Test accuracry: %.2f%%\" %(100*DNN_classifier.score((X_tst_, y_tst_))))\n",
    "\n",
    "y_tst_pred_ = DNN_classifier.predict(X_tst_)\n",
    "print(\"====================================================================\")\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_tst_, y_tst_pred_))\n",
    "print(\"====================================================================\")\n",
    "print(\"Classification report: \\n\", classification_report(y_tst_, y_tst_pred_, digits=4))\n",
    "print(\"====================================================================\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 1s 48ms/step - loss: 2.6799 - accuracy: 0.1892 - val_loss: 2.3546 - val_accuracy: 0.2381\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1652 - accuracy: 0.2901 - val_loss: 1.8825 - val_accuracy: 0.3571\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.7759 - accuracy: 0.4443 - val_loss: 1.6342 - val_accuracy: 0.4762\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.6206 - accuracy: 0.5045 - val_loss: 1.4516 - val_accuracy: 0.5714\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 1.3594 - accuracy: 0.5868 - val_loss: 1.3234 - val_accuracy: 0.5714\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.2013 - accuracy: 0.6488 - val_loss: 1.1949 - val_accuracy: 0.6190\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.1402 - accuracy: 0.6629 - val_loss: 1.0619 - val_accuracy: 0.6905\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.0496 - accuracy: 0.7187 - val_loss: 0.9832 - val_accuracy: 0.7143\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.9167 - accuracy: 0.7642 - val_loss: 0.8865 - val_accuracy: 0.7381\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8429 - accuracy: 0.7691 - val_loss: 0.8247 - val_accuracy: 0.7381\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7396 - accuracy: 0.8338 - val_loss: 0.7757 - val_accuracy: 0.7857\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7103 - accuracy: 0.8072 - val_loss: 0.7203 - val_accuracy: 0.8095\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6976 - accuracy: 0.8348 - val_loss: 0.6848 - val_accuracy: 0.8333\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.6398 - accuracy: 0.8210 - val_loss: 0.6495 - val_accuracy: 0.8095\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6071 - accuracy: 0.8596 - val_loss: 0.6129 - val_accuracy: 0.8333\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.5850 - accuracy: 0.8856 - val_loss: 0.5694 - val_accuracy: 0.8571\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5180 - accuracy: 0.8815 - val_loss: 0.5491 - val_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.5069 - accuracy: 0.8807 - val_loss: 0.5177 - val_accuracy: 0.8810\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4884 - accuracy: 0.8825 - val_loss: 0.4882 - val_accuracy: 0.8810\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4646 - accuracy: 0.9130 - val_loss: 0.4733 - val_accuracy: 0.8810\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4002 - accuracy: 0.9238 - val_loss: 0.4566 - val_accuracy: 0.8810\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4205 - accuracy: 0.9150 - val_loss: 0.4346 - val_accuracy: 0.9048\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4214 - accuracy: 0.9030 - val_loss: 0.4209 - val_accuracy: 0.9048\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3653 - accuracy: 0.9086 - val_loss: 0.4157 - val_accuracy: 0.9048\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.3755 - accuracy: 0.9030 - val_loss: 0.4097 - val_accuracy: 0.8810\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3631 - accuracy: 0.9127 - val_loss: 0.4060 - val_accuracy: 0.8810\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3654 - accuracy: 0.9270 - val_loss: 0.3901 - val_accuracy: 0.8810\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3322 - accuracy: 0.9339 - val_loss: 0.3661 - val_accuracy: 0.9286\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3194 - accuracy: 0.9274 - val_loss: 0.3446 - val_accuracy: 0.9286\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3163 - accuracy: 0.9349 - val_loss: 0.3425 - val_accuracy: 0.9286\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2949 - accuracy: 0.9600 - val_loss: 0.3344 - val_accuracy: 0.9286\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2645 - accuracy: 0.9630 - val_loss: 0.3398 - val_accuracy: 0.9048\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2609 - accuracy: 0.9433 - val_loss: 0.3421 - val_accuracy: 0.9048\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2510 - accuracy: 0.9429 - val_loss: 0.3342 - val_accuracy: 0.9048\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2138 - accuracy: 0.9620 - val_loss: 0.3241 - val_accuracy: 0.9286\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.2305 - accuracy: 0.9422 - val_loss: 0.3139 - val_accuracy: 0.9048\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 36ms/step - loss: 0.2305 - accuracy: 0.9608 - val_loss: 0.3224 - val_accuracy: 0.9048\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2212 - accuracy: 0.9543 - val_loss: 0.3651 - val_accuracy: 0.9286\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2278 - accuracy: 0.9595 - val_loss: 0.3122 - val_accuracy: 0.9048\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2271 - accuracy: 0.9459 - val_loss: 0.3114 - val_accuracy: 0.9048\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2018 - accuracy: 0.9530 - val_loss: 0.3732 - val_accuracy: 0.9048\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2155 - accuracy: 0.9666 - val_loss: 0.3354 - val_accuracy: 0.9048\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1835 - accuracy: 0.9724 - val_loss: 0.2965 - val_accuracy: 0.9048\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1790 - accuracy: 0.9705 - val_loss: 0.3218 - val_accuracy: 0.9048\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1904 - accuracy: 0.9567 - val_loss: 0.3181 - val_accuracy: 0.9048\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1565 - accuracy: 0.9847 - val_loss: 0.3030 - val_accuracy: 0.9048\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1621 - accuracy: 0.9754 - val_loss: 0.3190 - val_accuracy: 0.9286\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1768 - accuracy: 0.9687 - val_loss: 0.3030 - val_accuracy: 0.9286\n",
      "DNN accuracy: 0.96\n",
      "Training accuracry: 95.65%\n",
      "DNN accuracy: 0.78\n",
      "Test accuracry: 77.91%\n",
      "====================================================================\n",
      "Confusion matrix: \n",
      " [[1662   17    1  692   94  101   10    1]\n",
      " [   4 2558    1   14    6    3    0    0]\n",
      " [   4   20 2527   15    5    5    0    0]\n",
      " [ 328   15    1  997  543  671    6    0]\n",
      " [  16   18    2  343 2041  210    2   22]\n",
      " [ 310   20    4  442  241 1572    1    0]\n",
      " [  29   67   12   17    5    1 2399  115]\n",
      " [   2   14    3    8  100    5   20 2422]]\n",
      "====================================================================\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7057    0.6447    0.6738      2578\n",
      "           1     0.9373    0.9892    0.9626      2586\n",
      "           2     0.9906    0.9810    0.9858      2576\n",
      "           3     0.3944    0.3893    0.3918      2561\n",
      "           4     0.6725    0.7690    0.7175      2654\n",
      "           5     0.6121    0.6069    0.6095      2590\n",
      "           6     0.9840    0.9070    0.9439      2645\n",
      "           7     0.9461    0.9409    0.9435      2574\n",
      "\n",
      "    accuracy                         0.7791     20764\n",
      "   macro avg     0.7803    0.7785    0.7786     20764\n",
      "weighted avg     0.7808    0.7791    0.7791     20764\n",
      "\n",
      "====================================================================\n"
     ]
    }
   ],
   "source": [
    "# Without pretrain\n",
    "\n",
    "out_dir = './results/'\n",
    "DNN_classifier = DNN(dnn_hiddens=[100, 50, 20], output_size=8, out_directory=out_dir,\n",
    "                     pretrained_model=None, normalize=True, rate=0, n_epochs=100, pretrain_sae=False,\n",
    "                     pretrain_dagmm=False, monte_carlo=True)\n",
    "DNN_classifier.build_model(X_trn_)\n",
    "DNN_classifier.fit((X_trn_, y_trn_))\n",
    "\n",
    "print(\"Training accuracry: %.2f%%\" %(100*DNN_classifier.score((X_trn_, y_trn_))))\n",
    "print(\"Test accuracry: %.2f%%\" %(100*DNN_classifier.score((X_tst_, y_tst_))))\n",
    "\n",
    "y_tst_pred_ = DNN_classifier.predict(X_tst_)\n",
    "print(\"====================================================================\")\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_tst_, y_tst_pred_))\n",
    "print(\"====================================================================\")\n",
    "print(\"Classification report: \\n\", classification_report(y_tst_, y_tst_pred_, digits=4))\n",
    "print(\"====================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN MODEL:\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    2.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=7)\n",
      "Train Accuracy: 53.62318840579711 %\n",
      "Test Accuracy: 25.317857830861108 %\n",
      "====================================================================\n",
      "Confusion matrix: \n",
      " [[ 770  255  199  318  579  208  241    8]\n",
      " [ 779  443   37  241  618  196  264    8]\n",
      " [ 443  153 1176  158  394  239   13    0]\n",
      " [ 792  270  162  428  453  201  229   26]\n",
      " [ 825  271  130  425  512  202  205   84]\n",
      " [ 870  273  160  362  550  252  108   15]\n",
      " [ 513  172  131  194  352   81 1147   55]\n",
      " [ 582  116   82  166  654   98  347  529]]\n",
      "====================================================================\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1381    0.2987    0.1889      2578\n",
      "           1     0.2268    0.1713    0.1952      2586\n",
      "           2     0.5662    0.4565    0.5055      2576\n",
      "           3     0.1867    0.1671    0.1764      2561\n",
      "           4     0.1245    0.1929    0.1513      2654\n",
      "           5     0.1706    0.0973    0.1239      2590\n",
      "           6     0.4491    0.4336    0.4412      2645\n",
      "           7     0.7297    0.2055    0.3207      2574\n",
      "\n",
      "    accuracy                         0.2532     20764\n",
      "   macro avg     0.3240    0.2529    0.2629     20764\n",
      "weighted avg     0.3235    0.2532    0.2630     20764\n",
      "\n",
      "====================================================================\n",
      "SVM MODEL:\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "SVC(C=8, gamma=0.25)\n",
      "Train Accuracy: 99.51690821256038 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 45.26584473126565 %\n",
      "====================================================================\n",
      "Confusion matrix: \n",
      " [[ 971    1    0  418  392  207  501   88]\n",
      " [ 491  678    0   13  399   61  926   18]\n",
      " [   0    0 1237    0    0    0 1339    0]\n",
      " [ 427    0    0  717  732  203  348  134]\n",
      " [ 330    0    0  240 1283  157  400  244]\n",
      " [ 335    0    0  381  375  965  390  144]\n",
      " [  92    0    0   12  168    0 2134  239]\n",
      " [  48    0    0    0  516    0  596 1414]]\n",
      "====================================================================\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3604    0.3766    0.3684      2578\n",
      "           1     0.9985    0.2622    0.4153      2586\n",
      "           2     1.0000    0.4802    0.6488      2576\n",
      "           3     0.4026    0.2800    0.3303      2561\n",
      "           4     0.3320    0.4834    0.3936      2654\n",
      "           5     0.6058    0.3726    0.4614      2590\n",
      "           6     0.3217    0.8068    0.4600      2645\n",
      "           7     0.6199    0.5493    0.5825      2574\n",
      "\n",
      "    accuracy                         0.4527     20764\n",
      "   macro avg     0.5801    0.4514    0.4575     20764\n",
      "weighted avg     0.5786    0.4527    0.4574     20764\n",
      "\n",
      "====================================================================\n",
      "RANDOM FOREST MODEL:\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    1.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    1.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(n_estimators=200)\n",
      "Train Accuracy: 100.0 %\n",
      "Test Accuracy: 79.23328838374108 %\n",
      "====================================================================\n",
      "Confusion matrix: \n",
      " [[1540    0   28  657   41  299   13    0]\n",
      " [   0 2579    7    0    0    0    0    0]\n",
      " [   0    0 2576    0    0    0    0    0]\n",
      " [ 205    0    8 1270  543  524   11    0]\n",
      " [  48    0   12  366 2081  137    9    1]\n",
      " [ 348    0   13  454  428 1345    1    1]\n",
      " [  17    0   13   29    1    0 2583    2]\n",
      " [   0    0   10   22   59    1    4 2478]]\n",
      "====================================================================\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7136    0.5974    0.6503      2578\n",
      "           1     1.0000    0.9973    0.9986      2586\n",
      "           2     0.9659    1.0000    0.9826      2576\n",
      "           3     0.4539    0.4959    0.4740      2561\n",
      "           4     0.6600    0.7841    0.7167      2654\n",
      "           5     0.5833    0.5193    0.5494      2590\n",
      "           6     0.9855    0.9766    0.9810      2645\n",
      "           7     0.9984    0.9627    0.9802      2574\n",
      "\n",
      "    accuracy                         0.7923     20764\n",
      "   macro avg     0.7951    0.7917    0.7916     20764\n",
      "weighted avg     0.7954    0.7923    0.7921     20764\n",
      "\n",
      "====================================================================\n",
      "ADABOOST MODEL:\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  27 | elapsed:    1.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    1.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(learning_rate=0.1, n_estimators=200)\n",
      "Train Accuracy: 76.32850241545893 %\n",
      "Test Accuracy: 64.48661144288191 %\n",
      "====================================================================\n",
      "Confusion matrix: \n",
      " [[   0    0    0 1267  191 1078   42    0]\n",
      " [   0 2476    0  109    1    0    0    0]\n",
      " [   0    0 2575    1    0    0    0    0]\n",
      " [   0    0    0  641 1043  865   11    1]\n",
      " [   0    0    0  322 2182  139   10    1]\n",
      " [   0    0    0  198 1362 1029    1    0]\n",
      " [   0    0    0   54    5    0 2311  275]\n",
      " [   0    0    0   28  112    0  258 2176]]\n",
      "====================================================================\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.0000    0.0000    0.0000      2578\n",
      "           1     1.0000    0.9575    0.9783      2586\n",
      "           2     1.0000    0.9996    0.9998      2576\n",
      "           3     0.2447    0.2503    0.2474      2561\n",
      "           4     0.4457    0.8222    0.5780      2654\n",
      "           5     0.3308    0.3973    0.3610      2590\n",
      "           6     0.8777    0.8737    0.8757      2645\n",
      "           7     0.8871    0.8454    0.8657      2574\n",
      "\n",
      "    accuracy                         0.6449     20764\n",
      "   macro avg     0.5982    0.6432    0.6132     20764\n",
      "weighted avg     0.5988    0.6449    0.6142     20764\n",
      "\n",
      "====================================================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\travi\\anaconda3\\envs\\tf-gpu-pycharm\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1221: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "## 1. KNN MODEL\n",
    "\n",
    "print(\"KNN MODEL:\")\n",
    "\n",
    "k = [i for i in range(2,10)]\n",
    "p = [j for j in range(1,3)]\n",
    "param_grid = [{'n_neighbors': k, 'p': p}]\n",
    "knn_grid_search = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=3,\n",
    "                           scoring='f1_weighted', n_jobs=-1, return_train_score=True,\n",
    "                           verbose=1)\n",
    "\n",
    "knn_grid_search.fit(X_trn_scaled_, y_trn_)\n",
    "knn_clf = knn_grid_search.best_estimator_\n",
    "print(knn_clf)\n",
    "\n",
    "print(\"Train Accuracy:\", 100*knn_clf.score(X_trn_scaled_, y_trn_), chr(37))\n",
    "print(\"Test Accuracy:\", 100*knn_clf.score(X_tst_scaled_, y_tst_), chr(37))\n",
    "\n",
    "y_tst_pred_ = knn_clf.predict(X_tst_scaled_)\n",
    "print(\"====================================================================\")\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_tst_, y_tst_pred_))\n",
    "print(\"====================================================================\")\n",
    "print(\"Classification report: \\n\", classification_report(y_tst_, y_tst_pred_, digits=4))\n",
    "print(\"====================================================================\")\n",
    "\n",
    "## 2. SVM MODEL\n",
    "\n",
    "print(\"SVM MODEL:\")\n",
    "\n",
    "C = [2**i for i in range(0, 4)]\n",
    "gamma = [2**j for j in range(-2,2)]\n",
    "param_grid = [{'C': C, 'gamma': gamma}]\n",
    "svm_grid_search = GridSearchCV(SVC(), param_grid=param_grid, cv=3,\n",
    "                           scoring='f1_weighted', n_jobs=-1, return_train_score=True,\n",
    "                           verbose=1)\n",
    "svm_grid_search.fit(X_trn_scaled_, y_trn_)\n",
    "svm_clf = svm_grid_search.best_estimator_\n",
    "print(svm_clf)\n",
    "\n",
    "print(\"Train Accuracy:\", 100*svm_clf.score(X_trn_scaled_, y_trn_), chr(37))\n",
    "print(\"Test Accuracy:\", 100*svm_clf.score(X_tst_scaled_, y_tst_), chr(37))\n",
    "\n",
    "y_tst_pred_ = svm_clf.predict(X_tst_scaled_)\n",
    "print(\"====================================================================\")\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_tst_, y_tst_pred_))\n",
    "print(\"====================================================================\")\n",
    "print(\"Classification report: \\n\", classification_report(y_tst_, y_tst_pred_, digits=4))\n",
    "print(\"====================================================================\")\n",
    "\n",
    "## 3. RANDOM FOREST MODEL\n",
    "\n",
    "print(\"RANDOM FOREST MODEL:\")\n",
    "\n",
    "n_estimators_ = [int(x) for x in np.linspace(100, 550, 10)]\n",
    "\n",
    "param_grid = {'n_estimators':n_estimators_}\n",
    "rf_grid_search = GridSearchCV(RandomForestClassifier(), param_grid=param_grid, cv=3,\n",
    "                              scoring='f1_weighted', n_jobs=-1, return_train_score=True,\n",
    "                              verbose=1)\n",
    "rf_grid_search.fit(X_trn_, y_trn_)\n",
    "\n",
    "rf_clf = rf_grid_search.best_estimator_\n",
    "\n",
    "print(rf_clf)\n",
    "\n",
    "print(\"Train Accuracy:\", 100*rf_clf.score(X_trn_, y_trn_), chr(37))\n",
    "print(\"Test Accuracy:\", 100*rf_clf.score(X_tst_, y_tst_), chr(37))\n",
    "\n",
    "y_tst_pred_ = rf_clf.predict(X_tst_)\n",
    "print(\"====================================================================\")\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_tst_, y_tst_pred_))\n",
    "print(\"====================================================================\")\n",
    "print(\"Classification report: \\n\", classification_report(y_tst_, y_tst_pred_, digits=4))\n",
    "print(\"====================================================================\")\n",
    "\n",
    "\n",
    "\n",
    "# ## 4. LOGISTIC REGRESSION MODEL\n",
    "\n",
    "# C= np.logspace(-4,4,9)\n",
    "# solver=['newton-cg']\n",
    "\n",
    "# param_grid = [{'solver': solver, 'C': C}]\n",
    "# lr_grid_search = GridSearchCV(LogisticRegression(max_iter=100),\n",
    "#                            param_grid=param_grid, cv=3, scoring='f1_weighted',\n",
    "#                            n_jobs=-1, return_train_score=True, verbose=1)\n",
    "# lr_grid_search.fit(X_trn_scaled_, y_trn_)\n",
    "# lr_clf = lr_grid_search.best_estimator_\n",
    "# print(lr_clf)\n",
    "\n",
    "# print(\"Train Accuracy:\", 100*lr_clf.score(X_trn_scaled_, y_trn_), chr(37))\n",
    "# print(\"Test Accuracy:\", 100*lr_clf.score(X_tst_scaled_, y_tst_), chr(37))\n",
    "\n",
    "## 5. ADABOOST MODEL\n",
    "\n",
    "print(\"ADABOOST MODEL:\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators' : [100, 200, 300],\n",
    "    'learning_rate' : [0.001, 0.01, 0.1]\n",
    "}\n",
    "ad_grid_search = GridSearchCV(AdaBoostClassifier(), param_grid = param_grid,\n",
    "                                cv=3, scoring='f1_weighted', n_jobs=-1, return_train_score=True, verbose=1\n",
    "                                )\n",
    "ad_grid_search.fit(X_trn_, y_trn_)\n",
    "\n",
    "ad_clf = ad_grid_search.best_estimator_\n",
    "\n",
    "print(ad_clf)\n",
    "\n",
    "print(\"Train Accuracy:\", 100*ad_clf.score(X_trn_, y_trn_), chr(37))\n",
    "print(\"Test Accuracy:\", 100*ad_clf.score(X_tst_, y_tst_), chr(37))\n",
    "\n",
    "y_tst_pred_ = ad_clf.predict(X_tst_)\n",
    "print(\"====================================================================\")\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_tst_, y_tst_pred_))\n",
    "print(\"====================================================================\")\n",
    "print(\"Classification report: \\n\", classification_report(y_tst_, y_tst_pred_, digits=4))\n",
    "print(\"====================================================================\")\n",
    "\n",
    "\n",
    "# ## 6. GAUSIAN NAIVE BAYSESSIAN\n",
    "\n",
    "# params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "# gnb_grid_search = GridSearchCV(GaussianNB(), param_grid=params_NB, cv=3, scoring='accuracy',return_train_score=True)\n",
    "# gnb_grid_search.fit(X_trn_scaled_, y_trn_)\n",
    "\n",
    "# gnb_clf = gnb_grid_search.best_estimator_\n",
    "\n",
    "# print(gnb_clf)\n",
    "\n",
    "# print(\"Train Accuracy:\", 100*gnb_clf.score(X_trn_scaled_, y_trn_), chr(37))\n",
    "# print(\"Test Accuracy:\", 100*gnb_clf.score(X_tst_scaled_, y_tst_), chr(37))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 - GPU - Pycharm",
   "language": "python",
   "name": "tf-gpu-pycharm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
