{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import common libraries\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras as keras\n",
    "import tensorflow.keras.backend as K\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report\n",
    "import warnings\n",
    "warnings.filterwarnings(action=\"ignore\", message=\"^internal gelsd\")\n",
    "from dnn_INSE_6180 import DNN\n",
    "from dagmm_INSE_6180 import DAGMM\n",
    "from sae_INSE_6180 import SAE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_path = './datasets/chiller/df_dataset/'\n",
    "\n",
    "def load_data(load_path, filename):\n",
    "    csv_load_path = os.path.join(load_path, filename)\n",
    "    return pd.read_csv(csv_load_path)\n",
    "\n",
    "data = load_data(load_path, 'chiller10.csv') # Chiller data of Severity Level 1\n",
    "data = data.drop('Unnamed: 0', axis='columns')\n",
    "data_trn, data_tst = train_test_split(data, test_size=0.5, random_state=0)\n",
    "X_trn, y_trn = data_trn.iloc[:, :-1], data_trn.iloc[:, -1]\n",
    "X_tst, y_tst = data_tst.iloc[:, :-1], data_tst.iloc[:, -1]\n",
    "\n",
    "# Scale data\n",
    "scaler = StandardScaler().fit(X_trn)\n",
    "X_trn_scaled, X_tst_scaled = scaler.transform(X_trn), scaler.transform(X_tst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset 1 - 10% of Origninal data (2076 labeled data samples)\n",
    "data_trn_sub, _ = train_test_split(data_trn, test_size=0.9, random_state=0)\n",
    "X_trn_d1, y_trn_d1 = data_trn_sub.iloc[:, :-1], data_trn_sub.iloc[:, -1]\n",
    "\n",
    "# Scaling data\n",
    "X_trn_scaled_d1 = scaler.transform(X_trn_d1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset 2 - 3% of Origninal training data (622 labeled data samples)\n",
    "data_trn_sub, _ = train_test_split(data_trn, test_size=0.97, random_state=0)\n",
    "X_trn_d2, y_trn_d2 = data_trn_sub.iloc[:, :-1], data_trn_sub.iloc[:, -1]\n",
    "\n",
    "# Scaling data\n",
    "X_trn_scaled_d2 = scaler.transform(X_trn_d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset 3 - 1% of Origninal training data (207 labeled data samples)\n",
    "data_trn_sub, _ = train_test_split(data_trn, test_size=0.99, random_state=0)\n",
    "X_trn_d3, y_trn_d3 = data_trn_sub.iloc[:, :-1], data_trn_sub.iloc[:, -1]\n",
    "\n",
    "# Scaling data\n",
    "X_trn_scaled_d3 = scaler.transform(X_trn_d3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Dataset 4 - 0.5% of Origninal data (103 labeled data samples)\n",
    "data_trn_sub, _ = train_test_split(data_trn, test_size=0.995, random_state=0)\n",
    "X_trn_d4, y_trn_d4 = data_trn_sub.iloc[:, :-1], data_trn_sub.iloc[:, -1]\n",
    "\n",
    "# Scaling data\n",
    "X_trn_scaled_d4 = scaler.transform(X_trn_d4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Choose dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(207, 65)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "### Select labeled datasets with different sizes to test model\n",
    "\n",
    "# # Dataset 1 - 10% of Original dataset\n",
    "# X_trn_, X_tst_ = X_trn_d1, X_tst\n",
    "# X_trn_scaled_, X_tst_scaled_ = X_trn_scaled_d1, X_tst_scaled\n",
    "# y_trn_, y_tst_ = y_trn_d1, y_tst\n",
    "\n",
    "# # Dataset 2 - 3% of Origninal data\n",
    "# X_trn_, X_tst_ = X_trn_d2, X_tst\n",
    "# X_trn_scaled_, X_tst_scaled_ = X_trn_scaled_d2, X_tst_scaled\n",
    "# y_trn_, y_tst_ = y_trn_d2, y_tst\n",
    "\n",
    "## Dataset 3 - 1% of Origninal data\n",
    "X_trn_, X_tst_ = X_trn_d3, X_tst\n",
    "X_trn_scaled_, X_tst_scaled_ = X_trn_scaled_d3, X_tst_scaled\n",
    "y_trn_, y_tst_ = y_trn_d3, y_tst\n",
    "\n",
    "# ## Dataset 4 - 0.5% of Origninal data\n",
    "# X_trn_, X_tst_ = X_trn_d4, X_tst\n",
    "# X_trn_scaled_, X_tst_scaled_ = X_trn_scaled_d4, X_tst_scaled\n",
    "# y_trn_, y_tst_ = y_trn_d4, y_tst\n",
    "\n",
    "X_trn_.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN classifier without pretraining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "6/6 [==============================] - 2s 214ms/step - loss: 2.7399 - accuracy: 0.1130 - val_loss: 2.0887 - val_accuracy: 0.2143\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.1988 - accuracy: 0.2085 - val_loss: 1.8123 - val_accuracy: 0.3810\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.8561 - accuracy: 0.3673 - val_loss: 1.6187 - val_accuracy: 0.5000\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.5665 - accuracy: 0.5056 - val_loss: 1.4022 - val_accuracy: 0.6190\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.3713 - accuracy: 0.5820 - val_loss: 1.2613 - val_accuracy: 0.7143\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.1734 - accuracy: 0.7202 - val_loss: 1.1521 - val_accuracy: 0.7857\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.1096 - accuracy: 0.7605 - val_loss: 1.0813 - val_accuracy: 0.8095\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.9616 - accuracy: 0.7832 - val_loss: 1.0302 - val_accuracy: 0.7857\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.9567 - accuracy: 0.7778 - val_loss: 0.9179 - val_accuracy: 0.8333\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8897 - accuracy: 0.8266 - val_loss: 0.8233 - val_accuracy: 0.8095\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6923 - accuracy: 0.8321 - val_loss: 0.7732 - val_accuracy: 0.8095\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.7029 - accuracy: 0.7992 - val_loss: 0.6717 - val_accuracy: 0.8095\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6555 - accuracy: 0.8332 - val_loss: 0.6330 - val_accuracy: 0.8333\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.6184 - accuracy: 0.8466 - val_loss: 0.6237 - val_accuracy: 0.8095\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5757 - accuracy: 0.8375 - val_loss: 0.5892 - val_accuracy: 0.8095\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5305 - accuracy: 0.8440 - val_loss: 0.5608 - val_accuracy: 0.8095\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4716 - accuracy: 0.8772 - val_loss: 0.5316 - val_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4389 - accuracy: 0.8966 - val_loss: 0.4887 - val_accuracy: 0.8571\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.4319 - accuracy: 0.8951 - val_loss: 0.4761 - val_accuracy: 0.8571\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4079 - accuracy: 0.8832 - val_loss: 0.4506 - val_accuracy: 0.8810\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3622 - accuracy: 0.9126 - val_loss: 0.4480 - val_accuracy: 0.8571\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3749 - accuracy: 0.8884 - val_loss: 0.4380 - val_accuracy: 0.8810\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3599 - accuracy: 0.9026 - val_loss: 0.4234 - val_accuracy: 0.9048\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3091 - accuracy: 0.9338 - val_loss: 0.4520 - val_accuracy: 0.8571\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.3502 - accuracy: 0.9384 - val_loss: 0.3887 - val_accuracy: 0.9286\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2945 - accuracy: 0.9240 - val_loss: 0.3805 - val_accuracy: 0.9286\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2942 - accuracy: 0.9440 - val_loss: 0.3990 - val_accuracy: 0.9048\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3258 - accuracy: 0.9093 - val_loss: 0.3378 - val_accuracy: 0.9286\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2671 - accuracy: 0.9354 - val_loss: 0.3334 - val_accuracy: 0.9286\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 0.2477 - accuracy: 0.9593 - val_loss: 0.3378 - val_accuracy: 0.9286\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2577 - accuracy: 0.9623 - val_loss: 0.3411 - val_accuracy: 0.9286\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2540 - accuracy: 0.9377 - val_loss: 0.3505 - val_accuracy: 0.9286\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2305 - accuracy: 0.9750 - val_loss: 0.3623 - val_accuracy: 0.9286\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2445 - accuracy: 0.9496 - val_loss: 0.3467 - val_accuracy: 0.9286\n",
      "DNN accuracy: 0.94\n",
      "Training accuracry: 94.20%\n",
      "DNN accuracy: 0.77\n",
      "Test accuracry: 77.45%\n",
      "====================================================================\n",
      "Confusion matrix: \n",
      " [[1497   10    1  838   14  207   11    0]\n",
      " [   8 2420    0   41   99   11    3    4]\n",
      " [   1   10 2515   23    9   16    2    0]\n",
      " [ 368    7    0 1008  517  650   10    1]\n",
      " [ 164   11    3  175 2039  248    7    7]\n",
      " [ 263   13    0  386  359 1567    2    0]\n",
      " [   3   13    2   34    7    0 2581    5]\n",
      " [   0    9    1   22   82    0    6 2454]]\n",
      "====================================================================\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6497    0.5807    0.6133      2578\n",
      "           1     0.9707    0.9358    0.9529      2586\n",
      "           2     0.9972    0.9763    0.9867      2576\n",
      "           3     0.3989    0.3936    0.3962      2561\n",
      "           4     0.6523    0.7683    0.7055      2654\n",
      "           5     0.5806    0.6050    0.5926      2590\n",
      "           6     0.9844    0.9758    0.9801      2645\n",
      "           7     0.9931    0.9534    0.9728      2574\n",
      "\n",
      "    accuracy                         0.7745     20764\n",
      "   macro avg     0.7784    0.7736    0.7750     20764\n",
      "weighted avg     0.7788    0.7745    0.7756     20764\n",
      "\n",
      "====================================================================\n"
     ]
    }
   ],
   "source": [
    "# Without pretrain\n",
    "\n",
    "out_dir = './results/'\n",
    "\n",
    "# Create and train DNN_classifier\n",
    "DNN_classifier = DNN(dnn_hiddens=[100, 50, 20], output_size=8, out_directory=out_dir,\n",
    "                     pretrained_model=None, normalize=True, rate=0, n_epochs=100, pretrain_sae=False,\n",
    "                     pretrain_dagmm=False, monte_carlo=True)\n",
    "DNN_classifier.build_model(X_trn_)\n",
    "DNN_classifier.fit((X_trn_, y_trn_))\n",
    "\n",
    "print(\"Training accuracry: %.2f%%\" %(100*DNN_classifier.score((X_trn_, y_trn_))))\n",
    "print(\"Test accuracry: %.2f%%\" %(100*DNN_classifier.score((X_tst_, y_tst_))))\n",
    "\n",
    "y_tst_pred_ = DNN_classifier.predict(X_tst_)\n",
    "print(\"====================================================================\")\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_tst_, y_tst_pred_))\n",
    "print(\"====================================================================\")\n",
    "print(\"Classification report: \\n\", classification_report(y_tst_, y_tst_pred_, digits=4))\n",
    "print(\"====================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN classifier using SAE as pretrained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "553/584 [===========================>..] - ETA: 0s - loss: 5.5689WARNING:tensorflow:Layers in a Sequential model should only have a single input tensor, but we receive a <class 'tuple'> input: (<tf.Tensor 'IteratorGetNext:0' shape=(None, 65) dtype=float32>, <tf.Tensor 'IteratorGetNext:1' shape=(None, 65) dtype=float32>)\n",
      "Consider rewriting this model with the Functional API.\n",
      "584/584 [==============================] - 2s 2ms/step - loss: 5.4663 - val_loss: 1.1658\n",
      "Epoch 2/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 1.0721 - val_loss: 0.3446\n",
      "Epoch 3/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.5440 - val_loss: 0.2146\n",
      "Epoch 4/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.4194 - val_loss: 0.1838\n",
      "Epoch 5/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3683 - val_loss: 0.1715\n",
      "Epoch 6/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.4258 - val_loss: 0.1603\n",
      "Epoch 7/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3963 - val_loss: 0.1521\n",
      "Epoch 8/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3215 - val_loss: 0.1511\n",
      "Epoch 9/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3103 - val_loss: 0.1511\n",
      "Epoch 10/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3164 - val_loss: 0.1414\n",
      "Epoch 11/100\n",
      "584/584 [==============================] - 1s 2ms/step - loss: 0.3592 - val_loss: 0.1379\n",
      "Epoch 12/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3433 - val_loss: 0.1339\n",
      "Epoch 13/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3732 - val_loss: 0.1319\n",
      "Epoch 14/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3106 - val_loss: 0.1321\n",
      "Epoch 15/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3301 - val_loss: 0.1340\n",
      "Epoch 16/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3035 - val_loss: 0.1356\n",
      "Epoch 17/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3742 - val_loss: 0.1302\n",
      "Epoch 18/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3177 - val_loss: 0.1305\n",
      "Epoch 19/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3074 - val_loss: 0.1422\n",
      "Epoch 20/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3365 - val_loss: 0.1291\n",
      "Epoch 21/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3066 - val_loss: 0.1275\n",
      "Epoch 22/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.2896 - val_loss: 0.1242\n",
      "Epoch 23/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3228 - val_loss: 0.1239\n",
      "Epoch 24/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3110 - val_loss: 0.1353\n",
      "Epoch 25/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.2849 - val_loss: 0.1268\n",
      "Epoch 26/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.2908 - val_loss: 0.1523\n",
      "Epoch 27/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.4192 - val_loss: 0.1233\n",
      "Epoch 28/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.2750 - val_loss: 0.1254\n",
      "Epoch 29/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.2673 - val_loss: 0.1341\n",
      "Epoch 30/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.2865 - val_loss: 0.1277\n",
      "Epoch 31/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.3036 - val_loss: 0.1202\n",
      "Epoch 32/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.2713 - val_loss: 0.1246\n",
      "Epoch 33/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.2823 - val_loss: 0.1227\n",
      "Epoch 34/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.2634 - val_loss: 0.1247\n",
      "Epoch 35/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.2952 - val_loss: 0.1205\n",
      "Epoch 36/100\n",
      "584/584 [==============================] - 1s 1ms/step - loss: 0.2731 - val_loss: 0.1297\n"
     ]
    }
   ],
   "source": [
    "# Pretrain using SAE (Using SAE as pretrained model which is then used to pretrain DNN)\n",
    "\n",
    "out_dir = './results/'\n",
    "# create SAE model and train the model using unlabeled data\n",
    "model_sae = SAE(sae_hiddens=[100, 50, 20], out_directory = out_dir, dropout_rate=0, n_epochs=100, normalize=True)\n",
    "model_sae.build_model(X_trn) # X_trn is the unlabeled data ()\n",
    "model_sae.fit(X_trn) # Fit and save the best SAE model to the out_dir path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 44ms/step - loss: 2.1318 - accuracy: 0.1290 - val_loss: 2.1968 - val_accuracy: 0.0714\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.1488 - accuracy: 0.1440 - val_loss: 2.1851 - val_accuracy: 0.0714\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.1357 - accuracy: 0.1195 - val_loss: 2.1737 - val_accuracy: 0.0952\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.1303 - accuracy: 0.1251 - val_loss: 2.1595 - val_accuracy: 0.0952\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.0953 - accuracy: 0.1485 - val_loss: 2.1486 - val_accuracy: 0.0952\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 2.1128 - accuracy: 0.1317 - val_loss: 2.1385 - val_accuracy: 0.1190\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.1049 - accuracy: 0.1463 - val_loss: 2.1281 - val_accuracy: 0.1190\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.0659 - accuracy: 0.1583 - val_loss: 2.1186 - val_accuracy: 0.1190\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 2.1076 - accuracy: 0.1252 - val_loss: 2.1089 - val_accuracy: 0.1190\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 9ms/step - loss: 2.0681 - accuracy: 0.1372 - val_loss: 2.1014 - val_accuracy: 0.1190\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - 1s 44ms/step - loss: 2.0300 - accuracy: 0.1432 - val_loss: 2.0192 - val_accuracy: 0.2619\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.9929 - accuracy: 0.2109 - val_loss: 1.9508 - val_accuracy: 0.3333\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.9248 - accuracy: 0.3461 - val_loss: 1.8998 - val_accuracy: 0.3810\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.8832 - accuracy: 0.3754 - val_loss: 1.8365 - val_accuracy: 0.4762\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.8132 - accuracy: 0.4362 - val_loss: 1.7686 - val_accuracy: 0.4524\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.7405 - accuracy: 0.4641 - val_loss: 1.6907 - val_accuracy: 0.5476\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.6636 - accuracy: 0.5227 - val_loss: 1.5646 - val_accuracy: 0.5238\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.5358 - accuracy: 0.5421 - val_loss: 1.4504 - val_accuracy: 0.5476\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.3934 - accuracy: 0.6098 - val_loss: 1.3233 - val_accuracy: 0.5714\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.2606 - accuracy: 0.6089 - val_loss: 1.2381 - val_accuracy: 0.5476\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.1270 - accuracy: 0.5890 - val_loss: 1.0690 - val_accuracy: 0.6905\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 1.0061 - accuracy: 0.7064 - val_loss: 0.9701 - val_accuracy: 0.8095\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.9598 - accuracy: 0.7241 - val_loss: 0.8603 - val_accuracy: 0.8095\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8658 - accuracy: 0.7732 - val_loss: 0.7762 - val_accuracy: 0.7857\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.8058 - accuracy: 0.7979 - val_loss: 0.6935 - val_accuracy: 0.8095\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7426 - accuracy: 0.8098 - val_loss: 0.6090 - val_accuracy: 0.8810\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.6500 - accuracy: 0.8462 - val_loss: 0.5762 - val_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6347 - accuracy: 0.8353 - val_loss: 0.5221 - val_accuracy: 0.8810\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.5931 - accuracy: 0.8527 - val_loss: 0.4866 - val_accuracy: 0.8810\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.6175 - accuracy: 0.8071 - val_loss: 0.4608 - val_accuracy: 0.8810\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 0.4666 - accuracy: 0.8749 - val_loss: 0.4354 - val_accuracy: 0.9048\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5159 - accuracy: 0.8630 - val_loss: 0.4039 - val_accuracy: 0.9048\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.5274 - accuracy: 0.8212 - val_loss: 0.3889 - val_accuracy: 0.9286\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3936 - accuracy: 0.9082 - val_loss: 0.3669 - val_accuracy: 0.9286\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4352 - accuracy: 0.8956 - val_loss: 0.3965 - val_accuracy: 0.8571\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4468 - accuracy: 0.8340 - val_loss: 0.3149 - val_accuracy: 0.9286\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4368 - accuracy: 0.8541 - val_loss: 0.2963 - val_accuracy: 0.9048\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4195 - accuracy: 0.8703 - val_loss: 0.3022 - val_accuracy: 0.9048\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3666 - accuracy: 0.8977 - val_loss: 0.2773 - val_accuracy: 0.9048\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.4154 - accuracy: 0.8501 - val_loss: 0.2959 - val_accuracy: 0.9048\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3807 - accuracy: 0.8865 - val_loss: 0.2843 - val_accuracy: 0.9286\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3493 - accuracy: 0.8739 - val_loss: 0.2829 - val_accuracy: 0.9286\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3143 - accuracy: 0.9197 - val_loss: 0.2646 - val_accuracy: 0.9524\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2838 - accuracy: 0.9277 - val_loss: 0.2679 - val_accuracy: 0.9286\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2935 - accuracy: 0.9293 - val_loss: 0.2886 - val_accuracy: 0.9048\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3185 - accuracy: 0.8643 - val_loss: 0.2341 - val_accuracy: 0.9048\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2840 - accuracy: 0.9085 - val_loss: 0.2345 - val_accuracy: 0.9048\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2919 - accuracy: 0.9100 - val_loss: 0.2987 - val_accuracy: 0.9048\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3207 - accuracy: 0.9240 - val_loss: 0.2233 - val_accuracy: 0.9286\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.3181 - accuracy: 0.8873 - val_loss: 0.2117 - val_accuracy: 0.9286\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.2326 - accuracy: 0.9236 - val_loss: 0.4174 - val_accuracy: 0.8571\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3824 - accuracy: 0.8629 - val_loss: 0.2259 - val_accuracy: 0.9524\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2328 - accuracy: 0.9249 - val_loss: 0.2255 - val_accuracy: 0.9286\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.2807 - accuracy: 0.8774 - val_loss: 0.3352 - val_accuracy: 0.9286\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 10ms/step - loss: 0.3313 - accuracy: 0.9097 - val_loss: 0.2186 - val_accuracy: 0.9524\n",
      "DNN accuracy: 0.90\n",
      "Training accuracry: 90.34%\n",
      "DNN accuracy: 0.82\n",
      "Test accuracry: 82.06%\n",
      "====================================================================\n",
      "Confusion matrix: \n",
      " [[1736    0    2  441   68  322    9    0]\n",
      " [   1 2535    0   35    2    9    1    3]\n",
      " [   0    0 2529   39    0    7    1    0]\n",
      " [ 483    1    2  738  520  808    9    0]\n",
      " [  78    2    1   82 2325  164    2    0]\n",
      " [ 188    0    0  303   12 2086    1    0]\n",
      " [  10    0    3   39    5    3 2575   10]\n",
      " [   3    0    0   26    7    4   19 2515]]\n",
      "====================================================================\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.6947    0.6734    0.6839      2578\n",
      "           1     0.9988    0.9803    0.9895      2586\n",
      "           2     0.9968    0.9818    0.9892      2576\n",
      "           3     0.4334    0.2882    0.3462      2561\n",
      "           4     0.7911    0.8760    0.8314      2654\n",
      "           5     0.6130    0.8054    0.6961      2590\n",
      "           6     0.9840    0.9735    0.9787      2645\n",
      "           7     0.9949    0.9771    0.9859      2574\n",
      "\n",
      "    accuracy                         0.8206     20764\n",
      "   macro avg     0.8133    0.8195    0.8126     20764\n",
      "weighted avg     0.8140    0.8206    0.8135     20764\n",
      "\n",
      "====================================================================\n"
     ]
    }
   ],
   "source": [
    "# Using SAE to pretrain\n",
    "\n",
    "sae_model = model_sae.restore() # load sae_mode saved in the previous step\n",
    "\n",
    "# apply pretraining technique using sae_model as pretrained network\n",
    "DNN_classifier = DNN(dnn_hiddens=[100, 50, 20], output_size=8, out_directory=out_dir,\n",
    "                     pretrained_model=sae_model, normalize=True, rate=0, n_epochs=100, pretrain_sae=True, \n",
    "                     pretrain_dagmm=False, monte_carlo=True)\n",
    "DNN_classifier.build_model(X_trn_)\n",
    "DNN_classifier.fit((X_trn_, y_trn_))\n",
    "\n",
    "print(\"Training accuracry: %.2f%%\" %(100*DNN_classifier.score((X_trn_, y_trn_))))\n",
    "print(\"Test accuracry: %.2f%%\" %(100*DNN_classifier.score((X_tst_, y_tst_))))\n",
    "\n",
    "y_tst_pred_ = DNN_classifier.predict(X_tst_)\n",
    "print(\"====================================================================\")\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_tst_, y_tst_pred_))\n",
    "print(\"====================================================================\")\n",
    "print(\"Classification report: \\n\", classification_report(y_tst_, y_tst_pred_, digits=4))\n",
    "print(\"====================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DNN classifier using DAGMM as pretrained network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "20764/20764 [==============================] - mean_loss: 66.2602 - val_loss: 22.3701\n",
      "Best Epoch: 1\n",
      "Epoch 2/30\n",
      "20764/20764 [==============================] - mean_loss: 25.7874 - val_loss: 15.4399\n",
      "Best Epoch: 2\n",
      "Epoch 3/30\n",
      "20764/20764 [==============================] - mean_loss: 22.6745 - val_loss: 11.9801\n",
      "Best Epoch: 3\n",
      "Epoch 4/30\n",
      "20764/20764 [==============================] - mean_loss: 15.6502 - val_loss: 10.1659\n",
      "Best Epoch: 4\n",
      "Epoch 5/30\n",
      "20764/20764 [==============================] - mean_loss: 16.6603 - val_loss: 6.6004\n",
      "Best Epoch: 5\n",
      "Epoch 6/30\n",
      "20764/20764 [==============================] - mean_loss: 13.3023 - val_loss: 8.0818\n",
      "Best Epoch: 5\n",
      "Epoch 7/30\n",
      "20764/20764 [==============================] - mean_loss: 13.1718 - val_loss: 4.6557\n",
      "Best Epoch: 7\n",
      "Epoch 8/30\n",
      "20764/20764 [==============================] - mean_loss: 12.2453 - val_loss: 5.3291\n",
      "Best Epoch: 7\n",
      "Epoch 9/30\n",
      "20764/20764 [==============================] - mean_loss: 12.5681 - val_loss: 4.6998\n",
      "Best Epoch: 7\n",
      "Epoch 10/30\n",
      "20764/20764 [==============================] - mean_loss: 10.1321 - val_loss: 4.6546\n",
      "Best Epoch: 10\n",
      "Epoch 11/30\n",
      "20764/20764 [==============================] - mean_loss: 10.0778 - val_loss: 3.0309\n",
      "Best Epoch: 11\n",
      "Epoch 12/30\n",
      "20764/20764 [==============================] - mean_loss: 12.9146 - val_loss: 3.5035\n",
      "Best Epoch: 11\n",
      "Epoch 13/30\n",
      "20764/20764 [==============================] - mean_loss: 11.6875 - val_loss: 2.9343\n",
      "Best Epoch: 13\n",
      "Epoch 14/30\n",
      "20764/20764 [==============================] - mean_loss: 10.6343 - val_loss: 5.0501\n",
      "Best Epoch: 13\n",
      "Epoch 15/30\n",
      "20764/20764 [==============================] - mean_loss: 9.7270 - val_loss: 2.6104\n",
      "Best Epoch: 15\n",
      "Epoch 16/30\n",
      "20764/20764 [==============================] - mean_loss: 9.0498 - val_loss: 2.6551\n",
      "Best Epoch: 15\n",
      "Epoch 17/30\n",
      "20764/20764 [==============================] - mean_loss: 10.4817 - val_loss: 2.3684\n",
      "Best Epoch: 17\n",
      "Epoch 18/30\n",
      "20764/20764 [==============================] - mean_loss: 6.2714 - val_loss: 2.2941\n",
      "Best Epoch: 18\n",
      "Epoch 19/30\n",
      "20764/20764 [==============================] - mean_loss: 9.4021 - val_loss: 2.9500\n",
      "Best Epoch: 18\n",
      "Epoch 20/30\n",
      "20764/20764 [==============================] - mean_loss: 11.1379 - val_loss: 4.8191\n",
      "Best Epoch: 18\n",
      "Epoch 21/30\n",
      "20764/20764 [==============================] - mean_loss: 6.7233 - val_loss: 1.9026\n",
      "Best Epoch: 21\n",
      "Epoch 22/30\n",
      "20764/20764 [==============================] - mean_loss: 8.0685 - val_loss: 2.3496\n",
      "Best Epoch: 21\n",
      "Epoch 23/30\n",
      "20764/20764 [==============================] - mean_loss: 8.3168 - val_loss: 1.6546\n",
      "Best Epoch: 23\n",
      "Epoch 24/30\n",
      "20764/20764 [==============================] - mean_loss: 6.0539 - val_loss: 3.1122\n",
      "Best Epoch: 23\n",
      "Epoch 25/30\n",
      "20764/20764 [==============================] - mean_loss: 7.8948 - val_loss: 1.8444\n",
      "Best Epoch: 23\n",
      "Epoch 26/30\n",
      "20764/20764 [==============================] - mean_loss: 7.0650 - val_loss: 3.9174\n",
      "Best Epoch: 23\n",
      "Epoch 27/30\n",
      "20764/20764 [==============================] - mean_loss: 6.4815 - val_loss: 1.0217\n",
      "Best Epoch: 27\n",
      "Epoch 28/30\n",
      "20764/20764 [==============================] - mean_loss: 4.6973 - val_loss: 0.8492\n",
      "Best Epoch: 28\n",
      "Epoch 29/30\n",
      "20764/20764 [==============================] - mean_loss: 5.5214 - val_loss: 2.8969\n",
      "Best Epoch: 28\n",
      "Epoch 30/30\n",
      "20764/20764 [==============================] - mean_loss: 8.4260 - val_loss: 1.5428\n",
      "Best Epoch: 28\n"
     ]
    }
   ],
   "source": [
    "# Pretrain using DAGMM\n",
    "out_dir = './results/'\n",
    "# create dagmm model and train the model using unlabeled data\n",
    "model_dagmm = DAGMM(comp_hiddens=[100, 50, 20], comp_activation=\"elu\",\n",
    "                    est_hiddens=[10, 3], est_activation=\"elu\", est_dropout_ratio=0.1,\n",
    "                    n_epochs=30, batch_size=1024, normalize=True)\n",
    "model_dagmm.build(X_trn)\n",
    "model_dagmm.fit(X_trn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "6/6 [==============================] - 1s 45ms/step - loss: 2.2479 - accuracy: 0.1350 - val_loss: 2.2203 - val_accuracy: 0.0238\n",
      "Epoch 2/10\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 2.2367 - accuracy: 0.1089 - val_loss: 2.2106 - val_accuracy: 0.0476\n",
      "Epoch 3/10\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.2306 - accuracy: 0.1310 - val_loss: 2.2003 - val_accuracy: 0.0238\n",
      "Epoch 4/10\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.1955 - accuracy: 0.1235 - val_loss: 2.1890 - val_accuracy: 0.0476\n",
      "Epoch 5/10\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.2255 - accuracy: 0.1107 - val_loss: 2.1795 - val_accuracy: 0.0476\n",
      "Epoch 6/10\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.2576 - accuracy: 0.0802 - val_loss: 2.1699 - val_accuracy: 0.0476\n",
      "Epoch 7/10\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.1844 - accuracy: 0.1109 - val_loss: 2.1591 - val_accuracy: 0.0476\n",
      "Epoch 8/10\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.1633 - accuracy: 0.1064 - val_loss: 2.1494 - val_accuracy: 0.0476\n",
      "Epoch 9/10\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.1696 - accuracy: 0.1198 - val_loss: 2.1385 - val_accuracy: 0.0476\n",
      "Epoch 10/10\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 2.1832 - accuracy: 0.0973 - val_loss: 2.1301 - val_accuracy: 0.0714\n",
      "Epoch 1/100\n",
      "6/6 [==============================] - 1s 45ms/step - loss: 2.1080 - accuracy: 0.1577 - val_loss: 1.9878 - val_accuracy: 0.1667\n",
      "Epoch 2/100\n",
      "6/6 [==============================] - 0s 30ms/step - loss: 1.9408 - accuracy: 0.2247 - val_loss: 1.8565 - val_accuracy: 0.3333\n",
      "Epoch 3/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 1.7610 - accuracy: 0.4208 - val_loss: 1.7420 - val_accuracy: 0.4524\n",
      "Epoch 4/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.6248 - accuracy: 0.4659 - val_loss: 1.5958 - val_accuracy: 0.5952\n",
      "Epoch 5/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.5068 - accuracy: 0.6221 - val_loss: 1.4737 - val_accuracy: 0.7143\n",
      "Epoch 6/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.4155 - accuracy: 0.6562 - val_loss: 1.3267 - val_accuracy: 0.7381\n",
      "Epoch 7/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.2716 - accuracy: 0.6364 - val_loss: 1.1695 - val_accuracy: 0.7381\n",
      "Epoch 8/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 1.1659 - accuracy: 0.7172 - val_loss: 1.0503 - val_accuracy: 0.7381\n",
      "Epoch 9/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 1.0107 - accuracy: 0.7560 - val_loss: 0.9405 - val_accuracy: 0.7857\n",
      "Epoch 10/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.9462 - accuracy: 0.7713 - val_loss: 0.8479 - val_accuracy: 0.7857\n",
      "Epoch 11/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.8039 - accuracy: 0.8355 - val_loss: 0.7646 - val_accuracy: 0.8095\n",
      "Epoch 12/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.7277 - accuracy: 0.8145 - val_loss: 0.7063 - val_accuracy: 0.8333\n",
      "Epoch 13/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.7043 - accuracy: 0.8267 - val_loss: 0.6478 - val_accuracy: 0.8095\n",
      "Epoch 14/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6248 - accuracy: 0.8299 - val_loss: 0.6201 - val_accuracy: 0.7857\n",
      "Epoch 15/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.6177 - accuracy: 0.8313 - val_loss: 0.5749 - val_accuracy: 0.8095\n",
      "Epoch 16/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.5651 - accuracy: 0.8565 - val_loss: 0.5312 - val_accuracy: 0.8571\n",
      "Epoch 17/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4787 - accuracy: 0.9027 - val_loss: 0.5177 - val_accuracy: 0.8333\n",
      "Epoch 18/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.4770 - accuracy: 0.9033 - val_loss: 0.4764 - val_accuracy: 0.8810\n",
      "Epoch 19/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4358 - accuracy: 0.9035 - val_loss: 0.4547 - val_accuracy: 0.9048\n",
      "Epoch 20/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.4554 - accuracy: 0.8892 - val_loss: 0.4153 - val_accuracy: 0.8571\n",
      "Epoch 21/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3511 - accuracy: 0.9133 - val_loss: 0.3958 - val_accuracy: 0.9048\n",
      "Epoch 22/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3725 - accuracy: 0.9064 - val_loss: 0.3794 - val_accuracy: 0.9048\n",
      "Epoch 23/100\n",
      "6/6 [==============================] - 0s 14ms/step - loss: 0.3690 - accuracy: 0.8875 - val_loss: 0.3680 - val_accuracy: 0.9048\n",
      "Epoch 24/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2932 - accuracy: 0.9486 - val_loss: 0.3567 - val_accuracy: 0.9286\n",
      "Epoch 25/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3248 - accuracy: 0.9306 - val_loss: 0.3645 - val_accuracy: 0.9286\n",
      "Epoch 26/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3205 - accuracy: 0.9437 - val_loss: 0.3442 - val_accuracy: 0.9048\n",
      "Epoch 27/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.3078 - accuracy: 0.9348 - val_loss: 0.3219 - val_accuracy: 0.9048\n",
      "Epoch 28/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2850 - accuracy: 0.9164 - val_loss: 0.3149 - val_accuracy: 0.9048\n",
      "Epoch 29/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2657 - accuracy: 0.9315 - val_loss: 0.2942 - val_accuracy: 0.9286\n",
      "Epoch 30/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2903 - accuracy: 0.9266 - val_loss: 0.2940 - val_accuracy: 0.9286\n",
      "Epoch 31/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2576 - accuracy: 0.9209 - val_loss: 0.2765 - val_accuracy: 0.9048\n",
      "Epoch 32/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2365 - accuracy: 0.9294 - val_loss: 0.2801 - val_accuracy: 0.9048\n",
      "Epoch 33/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2225 - accuracy: 0.9455 - val_loss: 0.2834 - val_accuracy: 0.9048\n",
      "Epoch 34/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2048 - accuracy: 0.9667 - val_loss: 0.2720 - val_accuracy: 0.9048\n",
      "Epoch 35/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1867 - accuracy: 0.9624 - val_loss: 0.3097 - val_accuracy: 0.8810\n",
      "Epoch 36/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2238 - accuracy: 0.9418 - val_loss: 0.2611 - val_accuracy: 0.9048\n",
      "Epoch 37/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1942 - accuracy: 0.9422 - val_loss: 0.2696 - val_accuracy: 0.9048\n",
      "Epoch 38/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2046 - accuracy: 0.9552 - val_loss: 0.2964 - val_accuracy: 0.9048\n",
      "Epoch 39/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2179 - accuracy: 0.9185 - val_loss: 0.2503 - val_accuracy: 0.9048\n",
      "Epoch 40/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.2128 - accuracy: 0.9362 - val_loss: 0.2521 - val_accuracy: 0.9048\n",
      "Epoch 41/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1780 - accuracy: 0.9513 - val_loss: 0.3849 - val_accuracy: 0.8571\n",
      "Epoch 42/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.2485 - accuracy: 0.9550 - val_loss: 0.2840 - val_accuracy: 0.9048\n",
      "Epoch 43/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1706 - accuracy: 0.9628 - val_loss: 0.2499 - val_accuracy: 0.9048\n",
      "Epoch 44/100\n",
      "6/6 [==============================] - 0s 13ms/step - loss: 0.1776 - accuracy: 0.9586 - val_loss: 0.2753 - val_accuracy: 0.9048\n",
      "Epoch 45/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1842 - accuracy: 0.9455 - val_loss: 0.2593 - val_accuracy: 0.9048\n",
      "Epoch 46/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1312 - accuracy: 0.9781 - val_loss: 0.2432 - val_accuracy: 0.9048\n",
      "Epoch 47/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1622 - accuracy: 0.9590 - val_loss: 0.2476 - val_accuracy: 0.9286\n",
      "Epoch 48/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1513 - accuracy: 0.9441 - val_loss: 0.2472 - val_accuracy: 0.9286\n",
      "Epoch 49/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1277 - accuracy: 0.9821 - val_loss: 0.2548 - val_accuracy: 0.9286\n",
      "Epoch 50/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1183 - accuracy: 0.9787 - val_loss: 0.2428 - val_accuracy: 0.9286\n",
      "Epoch 51/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1199 - accuracy: 0.9809 - val_loss: 0.2521 - val_accuracy: 0.9286\n",
      "Epoch 52/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1154 - accuracy: 0.9869 - val_loss: 0.2390 - val_accuracy: 0.9286\n",
      "Epoch 53/100\n",
      "6/6 [==============================] - 0s 11ms/step - loss: 0.1189 - accuracy: 0.9817 - val_loss: 0.2423 - val_accuracy: 0.9286\n",
      "Epoch 54/100\n",
      "6/6 [==============================] - 0s 33ms/step - loss: 0.1175 - accuracy: 0.9869 - val_loss: 0.2337 - val_accuracy: 0.9286\n",
      "Epoch 55/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1141 - accuracy: 0.9791 - val_loss: 0.2236 - val_accuracy: 0.9286\n",
      "Epoch 56/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1129 - accuracy: 0.9705 - val_loss: 0.2239 - val_accuracy: 0.9286\n",
      "Epoch 57/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1183 - accuracy: 0.9806 - val_loss: 0.2182 - val_accuracy: 0.9048\n",
      "Epoch 58/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0898 - accuracy: 0.9948 - val_loss: 0.2153 - val_accuracy: 0.9286\n",
      "Epoch 59/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0930 - accuracy: 0.9855 - val_loss: 0.2555 - val_accuracy: 0.9286\n",
      "Epoch 60/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.1369 - accuracy: 0.9590 - val_loss: 0.2388 - val_accuracy: 0.9286\n",
      "Epoch 61/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0863 - accuracy: 0.9921 - val_loss: 0.2260 - val_accuracy: 0.9286\n",
      "Epoch 62/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0821 - accuracy: 0.9936 - val_loss: 0.2213 - val_accuracy: 0.9286\n",
      "Epoch 63/100\n",
      "6/6 [==============================] - 0s 12ms/step - loss: 0.0935 - accuracy: 0.9806 - val_loss: 0.2279 - val_accuracy: 0.9286\n",
      "DNN accuracy: 0.98\n",
      "Training accuracry: 97.58%\n",
      "DNN accuracy: 0.84\n",
      "Test accuracry: 84.45%\n",
      "====================================================================\n",
      "Confusion matrix: \n",
      " [[1973   10    0  505   26   58    6    0]\n",
      " [   8 2547    0   12    2   17    0    0]\n",
      " [   7   10 2525   21    0   13    0    0]\n",
      " [ 425    8    0 1317  356  444    7    4]\n",
      " [  31   11    0  278 2171  151    4    8]\n",
      " [ 197   13    0  364  110 1906    0    0]\n",
      " [  24   12    1   30    2    1 2570    5]\n",
      " [   7    9    0   18    3    3    7 2527]]\n",
      "====================================================================\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7384    0.7653    0.7516      2578\n",
      "           1     0.9721    0.9849    0.9785      2586\n",
      "           2     0.9996    0.9802    0.9898      2576\n",
      "           3     0.5175    0.5143    0.5159      2561\n",
      "           4     0.8131    0.8180    0.8156      2654\n",
      "           5     0.7351    0.7359    0.7355      2590\n",
      "           6     0.9907    0.9716    0.9811      2645\n",
      "           7     0.9933    0.9817    0.9875      2574\n",
      "\n",
      "    accuracy                         0.8445     20764\n",
      "   macro avg     0.8450    0.8440    0.8444     20764\n",
      "weighted avg     0.8455    0.8445    0.8450     20764\n",
      "\n",
      "====================================================================\n"
     ]
    }
   ],
   "source": [
    "# Using DAGMM to pretrain DNN\n",
    "\n",
    "dagmm_model = model_dagmm.restore() # load dagmm model saved in the previous step\n",
    "out_dir = './results/'\n",
    "\n",
    "# apply pretraining technique using dagmm as pretrained network\n",
    "DNN_classifier = DNN(dnn_hiddens=[100, 50, 20], output_size=8, out_directory=out_dir,\n",
    "                     pretrained_model=dagmm_model, normalize=True, rate=0, n_epochs=100, pretrain_sae=False,\n",
    "                     pretrain_dagmm=True, monte_carlo=True)\n",
    "DNN_classifier.build_model(X_trn_)\n",
    "DNN_classifier.fit((X_trn_, y_trn_))\n",
    "\n",
    "print(\"Training accuracry: %.2f%%\" %(100*DNN_classifier.score((X_trn_, y_trn_))))\n",
    "print(\"Test accuracry: %.2f%%\" %(100*DNN_classifier.score((X_tst_, y_tst_))))\n",
    "\n",
    "y_tst_pred_ = DNN_classifier.predict(X_tst_)\n",
    "print(\"====================================================================\")\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_tst_, y_tst_pred_))\n",
    "print(\"====================================================================\")\n",
    "print(\"Classification report: \\n\", classification_report(y_tst_, y_tst_pred_, digits=4))\n",
    "print(\"====================================================================\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Baseline models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNN MODEL:\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    2.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KNeighborsClassifier(n_neighbors=7)\n",
      "Train Accuracy: 53.62318840579711 %\n",
      "Test Accuracy: 25.317857830861108 %\n",
      "====================================================================\n",
      "Confusion matrix: \n",
      " [[ 770  255  199  318  579  208  241    8]\n",
      " [ 779  443   37  241  618  196  264    8]\n",
      " [ 443  153 1176  158  394  239   13    0]\n",
      " [ 792  270  162  428  453  201  229   26]\n",
      " [ 825  271  130  425  512  202  205   84]\n",
      " [ 870  273  160  362  550  252  108   15]\n",
      " [ 513  172  131  194  352   81 1147   55]\n",
      " [ 582  116   82  166  654   98  347  529]]\n",
      "====================================================================\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.1381    0.2987    0.1889      2578\n",
      "           1     0.2268    0.1713    0.1952      2586\n",
      "           2     0.5662    0.4565    0.5055      2576\n",
      "           3     0.1867    0.1671    0.1764      2561\n",
      "           4     0.1245    0.1929    0.1513      2654\n",
      "           5     0.1706    0.0973    0.1239      2590\n",
      "           6     0.4491    0.4336    0.4412      2645\n",
      "           7     0.7297    0.2055    0.3207      2574\n",
      "\n",
      "    accuracy                         0.2532     20764\n",
      "   macro avg     0.3240    0.2529    0.2629     20764\n",
      "weighted avg     0.3235    0.2532    0.2630     20764\n",
      "\n",
      "====================================================================\n",
      "SVM MODEL:\n",
      "Fitting 3 folds for each of 16 candidates, totalling 48 fits\n",
      "SVC(C=8, gamma=0.25)\n",
      "Train Accuracy: 99.51690821256038 %\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  48 out of  48 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 45.26584473126565 %\n",
      "====================================================================\n",
      "Confusion matrix: \n",
      " [[ 971    1    0  418  392  207  501   88]\n",
      " [ 491  678    0   13  399   61  926   18]\n",
      " [   0    0 1237    0    0    0 1339    0]\n",
      " [ 427    0    0  717  732  203  348  134]\n",
      " [ 330    0    0  240 1283  157  400  244]\n",
      " [ 335    0    0  381  375  965  390  144]\n",
      " [  92    0    0   12  168    0 2134  239]\n",
      " [  48    0    0    0  516    0  596 1414]]\n",
      "====================================================================\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.3604    0.3766    0.3684      2578\n",
      "           1     0.9985    0.2622    0.4153      2586\n",
      "           2     1.0000    0.4802    0.6488      2576\n",
      "           3     0.4026    0.2800    0.3303      2561\n",
      "           4     0.3320    0.4834    0.3936      2654\n",
      "           5     0.6058    0.3726    0.4614      2590\n",
      "           6     0.3217    0.8068    0.4600      2645\n",
      "           7     0.6199    0.5493    0.5825      2574\n",
      "\n",
      "    accuracy                         0.4527     20764\n",
      "   macro avg     0.5801    0.4514    0.4575     20764\n",
      "weighted avg     0.5786    0.4527    0.4574     20764\n",
      "\n",
      "====================================================================\n",
      "RANDOM FOREST MODEL:\n",
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    1.6s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  30 out of  30 | elapsed:    1.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomForestClassifier(n_estimators=250)\n",
      "Train Accuracy: 100.0 %\n",
      "Test Accuracy: 79.47408977075709 %\n",
      "====================================================================\n",
      "Confusion matrix: \n",
      " [[1549    0   33  673   25  285   13    0]\n",
      " [   0 2579    7    0    0    0    0    0]\n",
      " [   0    0 2576    0    0    0    0    0]\n",
      " [ 170    0    8 1304  529  539   11    0]\n",
      " [  45    0   12  376 2067  144    8    2]\n",
      " [ 344    0   13  436  422 1373    1    1]\n",
      " [  20    0   13   33    0    0 2576    3]\n",
      " [   0    0   10   25   57    0    4 2478]]\n",
      "====================================================================\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.7279    0.6009    0.6583      2578\n",
      "           1     1.0000    0.9973    0.9986      2586\n",
      "           2     0.9641    1.0000    0.9817      2576\n",
      "           3     0.4580    0.5092    0.4822      2561\n",
      "           4     0.6668    0.7788    0.7185      2654\n",
      "           5     0.5865    0.5301    0.5569      2590\n",
      "           6     0.9858    0.9739    0.9798      2645\n",
      "           7     0.9976    0.9627    0.9798      2574\n",
      "\n",
      "    accuracy                         0.7947     20764\n",
      "   macro avg     0.7983    0.7941    0.7945     20764\n",
      "weighted avg     0.7986    0.7947    0.7950     20764\n",
      "\n",
      "====================================================================\n",
      "ADABOOST MODEL:\n",
      "Fitting 3 folds for each of 9 candidates, totalling 27 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  24 out of  27 | elapsed:    0.9s remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done  27 out of  27 | elapsed:    1.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AdaBoostClassifier(learning_rate=0.01, n_estimators=100)\n",
      "Train Accuracy: 79.22705314009661 %\n",
      "Test Accuracy: 72.30784049316124 %\n",
      "====================================================================\n",
      "Confusion matrix: \n",
      " [[ 951    0   10  269  115 1191   42    0]\n",
      " [   0 2578    7    0    1    0    0    0]\n",
      " [   0    0 2576    0    0    0    0    0]\n",
      " [ 148    0    7  328  898 1168   11    1]\n",
      " [   0    0   12  154 2463   14   10    1]\n",
      " [  30    0   13  225 1174 1147    1    0]\n",
      " [   4    0   13   14   26    2 2570   16]\n",
      " [   0    0   10    4  116   10   33 2401]]\n",
      "====================================================================\n",
      "Classification report: \n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.8394    0.3689    0.5125      2578\n",
      "           1     1.0000    0.9969    0.9985      2586\n",
      "           2     0.9728    1.0000    0.9862      2576\n",
      "           3     0.3300    0.1281    0.1845      2561\n",
      "           4     0.5139    0.9280    0.6615      2654\n",
      "           5     0.3247    0.4429    0.3747      2590\n",
      "           6     0.9636    0.9716    0.9676      2645\n",
      "           7     0.9926    0.9328    0.9617      2574\n",
      "\n",
      "    accuracy                         0.7231     20764\n",
      "   macro avg     0.7421    0.7211    0.7059     20764\n",
      "weighted avg     0.7421    0.7231    0.7069     20764\n",
      "\n",
      "====================================================================\n"
     ]
    }
   ],
   "source": [
    "## 1. KNN MODEL\n",
    "\n",
    "print(\"KNN MODEL:\")\n",
    "\n",
    "k = [i for i in range(2,10)]\n",
    "p = [j for j in range(1,3)]\n",
    "param_grid = [{'n_neighbors': k, 'p': p}]\n",
    "knn_grid_search = GridSearchCV(KNeighborsClassifier(), param_grid=param_grid, cv=3,\n",
    "                           scoring='f1_weighted', n_jobs=-1, return_train_score=True,\n",
    "                           verbose=1)\n",
    "\n",
    "knn_grid_search.fit(X_trn_scaled_, y_trn_)\n",
    "knn_clf = knn_grid_search.best_estimator_\n",
    "print(knn_clf)\n",
    "\n",
    "print(\"Train Accuracy:\", 100*knn_clf.score(X_trn_scaled_, y_trn_), chr(37))\n",
    "print(\"Test Accuracy:\", 100*knn_clf.score(X_tst_scaled_, y_tst_), chr(37))\n",
    "\n",
    "y_tst_pred_ = knn_clf.predict(X_tst_scaled_)\n",
    "print(\"====================================================================\")\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_tst_, y_tst_pred_))\n",
    "print(\"====================================================================\")\n",
    "print(\"Classification report: \\n\", classification_report(y_tst_, y_tst_pred_, digits=4))\n",
    "print(\"====================================================================\")\n",
    "\n",
    "## 2. SVM MODEL\n",
    "\n",
    "print(\"SVM MODEL:\")\n",
    "\n",
    "C = [2**i for i in range(0, 4)]\n",
    "gamma = [2**j for j in range(-2,2)]\n",
    "param_grid = [{'C': C, 'gamma': gamma}]\n",
    "svm_grid_search = GridSearchCV(SVC(), param_grid=param_grid, cv=3,\n",
    "                           scoring='f1_weighted', n_jobs=-1, return_train_score=True,\n",
    "                           verbose=1)\n",
    "svm_grid_search.fit(X_trn_scaled_, y_trn_)\n",
    "svm_clf = svm_grid_search.best_estimator_\n",
    "print(svm_clf)\n",
    "\n",
    "print(\"Train Accuracy:\", 100*svm_clf.score(X_trn_scaled_, y_trn_), chr(37))\n",
    "print(\"Test Accuracy:\", 100*svm_clf.score(X_tst_scaled_, y_tst_), chr(37))\n",
    "\n",
    "y_tst_pred_ = svm_clf.predict(X_tst_scaled_)\n",
    "print(\"====================================================================\")\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_tst_, y_tst_pred_))\n",
    "print(\"====================================================================\")\n",
    "print(\"Classification report: \\n\", classification_report(y_tst_, y_tst_pred_, digits=4))\n",
    "print(\"====================================================================\")\n",
    "\n",
    "## 3. RANDOM FOREST MODEL\n",
    "\n",
    "print(\"RANDOM FOREST MODEL:\")\n",
    "\n",
    "n_estimators_ = [int(x) for x in np.linspace(100, 550, 10)]\n",
    "\n",
    "param_grid = {'n_estimators':n_estimators_}\n",
    "rf_grid_search = GridSearchCV(RandomForestClassifier(), param_grid=param_grid, cv=3,\n",
    "                              scoring='f1_weighted', n_jobs=-1, return_train_score=True,\n",
    "                              verbose=1)\n",
    "rf_grid_search.fit(X_trn_, y_trn_)\n",
    "\n",
    "rf_clf = rf_grid_search.best_estimator_\n",
    "\n",
    "print(rf_clf)\n",
    "\n",
    "print(\"Train Accuracy:\", 100*rf_clf.score(X_trn_, y_trn_), chr(37))\n",
    "print(\"Test Accuracy:\", 100*rf_clf.score(X_tst_, y_tst_), chr(37))\n",
    "\n",
    "y_tst_pred_ = rf_clf.predict(X_tst_)\n",
    "print(\"====================================================================\")\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_tst_, y_tst_pred_))\n",
    "print(\"====================================================================\")\n",
    "print(\"Classification report: \\n\", classification_report(y_tst_, y_tst_pred_, digits=4))\n",
    "print(\"====================================================================\")\n",
    "\n",
    "\n",
    "\n",
    "# ## 4. LOGISTIC REGRESSION MODEL\n",
    "\n",
    "# C= np.logspace(-4,4,9)\n",
    "# solver=['newton-cg']\n",
    "\n",
    "# param_grid = [{'solver': solver, 'C': C}]\n",
    "# lr_grid_search = GridSearchCV(LogisticRegression(max_iter=100),\n",
    "#                            param_grid=param_grid, cv=3, scoring='f1_weighted',\n",
    "#                            n_jobs=-1, return_train_score=True, verbose=1)\n",
    "# lr_grid_search.fit(X_trn_scaled_, y_trn_)\n",
    "# lr_clf = lr_grid_search.best_estimator_\n",
    "# print(lr_clf)\n",
    "\n",
    "# print(\"Train Accuracy:\", 100*lr_clf.score(X_trn_scaled_, y_trn_), chr(37))\n",
    "# print(\"Test Accuracy:\", 100*lr_clf.score(X_tst_scaled_, y_tst_), chr(37))\n",
    "\n",
    "## 5. ADABOOST MODEL\n",
    "\n",
    "print(\"ADABOOST MODEL:\")\n",
    "\n",
    "param_grid = {\n",
    "    'n_estimators' : [100, 200, 300],\n",
    "    'learning_rate' : [0.001, 0.01, 0.1]\n",
    "}\n",
    "ad_grid_search = GridSearchCV(AdaBoostClassifier(), param_grid = param_grid,\n",
    "                                cv=3, scoring='f1_weighted', n_jobs=-1, return_train_score=True, verbose=1\n",
    "                                )\n",
    "ad_grid_search.fit(X_trn_, y_trn_)\n",
    "\n",
    "ad_clf = ad_grid_search.best_estimator_\n",
    "\n",
    "print(ad_clf)\n",
    "\n",
    "print(\"Train Accuracy:\", 100*ad_clf.score(X_trn_, y_trn_), chr(37))\n",
    "print(\"Test Accuracy:\", 100*ad_clf.score(X_tst_, y_tst_), chr(37))\n",
    "\n",
    "y_tst_pred_ = ad_clf.predict(X_tst_)\n",
    "print(\"====================================================================\")\n",
    "print(\"Confusion matrix: \\n\", confusion_matrix(y_tst_, y_tst_pred_))\n",
    "print(\"====================================================================\")\n",
    "print(\"Classification report: \\n\", classification_report(y_tst_, y_tst_pred_, digits=4))\n",
    "print(\"====================================================================\")\n",
    "\n",
    "\n",
    "# ## 6. GAUSIAN NAIVE BAYSESSIAN\n",
    "\n",
    "# params_NB = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "# gnb_grid_search = GridSearchCV(GaussianNB(), param_grid=params_NB, cv=3, scoring='accuracy',return_train_score=True)\n",
    "# gnb_grid_search.fit(X_trn_scaled_, y_trn_)\n",
    "\n",
    "# gnb_clf = gnb_grid_search.best_estimator_\n",
    "\n",
    "# print(gnb_clf)\n",
    "\n",
    "# print(\"Train Accuracy:\", 100*gnb_clf.score(X_trn_scaled_, y_trn_), chr(37))\n",
    "# print(\"Test Accuracy:\", 100*gnb_clf.score(X_tst_scaled_, y_tst_), chr(37))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 - GPU - Pycharm",
   "language": "python",
   "name": "tf-gpu-pycharm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
